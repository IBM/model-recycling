---
layout: default
title: google_t5-v1_1-base
parent: Rankings
has_children: true
---
[comment]: # (This page contains a link to a table with the ranking and performance of all ranked google_t5-v1_1-base models. In addition, it contains a table with the baseline and the 10 best models. The original ranking was done by finetuning only the classification head of the model (linear probing) over the MNLI dataset.  The best models  by this ranking where ranked by the average accuracy after finetuning over the 36 datasets (except for the stsb dataset, where we used the Spearman correlation instead of accuracy).)

Ranking and performance of all ranked google_t5-v1_1-base models ([full table](./results/google_t5-v1_1-base_table.csv)).

Notes:
1. The baseline results can be found [here](google_t5-v1_1-base_pretrain_scores_table)
1. While the average improvement is small, many datasets show large gains.
<br>


|            | model_name                                            | avg     | mnli_lp   | 20_newsgroup   | ag_news   | amazon_reviews_multi   | anli    | boolq   | cb      | cola    | copa    | dbpedia   | esnli   | financial_phrasebank   | imdb    | isear   | mnli    | mrpc    | multirc   | poem_sentiment   | qnli    | qqp     | rotten_tomatoes   | rte     | sst2    | sst_5bins   | stsb    | trec_coarse   | trec_fine   | tweet_ev_emoji   | tweet_ev_emotion   | tweet_ev_hate   | tweet_ev_irony   | tweet_ev_offensive   | tweet_ev_sentiment   | wic     | wnli    | wsc     | yahoo_answers   |
|:-----------|:------------------------------------------------------|:--------|:----------|:---------------|:----------|:-----------------------|:--------|:--------|:--------|:--------|:--------|:----------|:--------|:-----------------------|:--------|:--------|:--------|:--------|:----------|:-----------------|:--------|:--------|:------------------|:--------|:--------|:------------|:--------|:--------------|:------------|:-----------------|:-------------------|:----------------|:-----------------|:---------------------|:---------------------|:--------|:--------|:--------|:----------------|
| *baseline* | *google/t5-v1_1-base*                                 | *68.82* | *nan*     | *82.88*        | *88.18*   | *66.91*                | *38.06* | *65.57* | *55.45* | *70.18* | *40.50* | *70.77*   | *85.58* | *66.74*                | *92.99* | *71.06* | *75.51* | *72.83* | *56.14*   | *68.08*          | *89.37* | *83.60* | *86.05*           | *60.58* | *93.72* | *51.84*     | *68.79* | *93.25*       | *82.07*     | *33.46*          | *75.61*            | *51.52*         | *67.62*          | *82.61*              | *69.88*              | *55.84* | *46.90* | *48.32* | *69.26*         |
| 1          | ClueAI/PromptCLUE                                     | nan     | 0.00      | nan            | nan       | nan                    | nan     | nan     | nan     | nan     | nan     | nan       | nan     | nan                    | nan     | nan     | nan     | nan     | nan       | nan              | nan     | nan     | nan               | nan     | nan     | nan         | nan     | nan           | nan         | nan              | nan                | nan             | nan              | nan                  | nan                  | nan     | nan     | nan     | nan             |
| 2          | ClueAI/PromptCLUE-base                                | nan     | 0.00      | nan            | nan       | nan                    | nan     | nan     | nan     | nan     | nan     | nan       | nan     | nan                    | nan     | nan     | nan     | nan     | nan       | nan              | nan     | nan     | nan               | nan     | nan     | nan         | nan     | nan           | nan         | nan              | nan                | nan             | nan              | nan                  | nan                  | nan     | nan     | nan     | nan             |
| 3          | anshoomehra/t5-v1_1-base-squadAndQnliAutoQgenAutoQgen | nan     | 0.00      | nan            | nan       | nan                    | nan     | nan     | nan     | nan     | nan     | nan       | nan     | nan                    | nan     | nan     | nan     | nan     | nan       | nan              | nan     | nan     | nan               | nan     | nan     | nan         | nan     | nan           | nan         | nan              | nan                | nan             | nan              | nan                  | nan                  | nan     | nan     | nan     | nan             |
| 4          | anshoomehra/temp                                      | nan     | 0.00      | nan            | nan       | nan                    | nan     | nan     | nan     | nan     | nan     | nan       | nan     | nan                    | nan     | nan     | nan     | nan     | nan       | nan              | nan     | nan     | nan               | nan     | nan     | nan         | nan     | nan           | nan         | nan              | nan                | nan             | nan              | nan                  | nan                  | nan     | nan     | nan     | nan             |
| 5          | binxu/mengzi-t5-base-finetuned-punctuation            | nan     | 0.00      | nan            | nan       | nan                    | nan     | nan     | nan     | nan     | nan     | nan       | nan     | nan                    | nan     | nan     | nan     | nan     | nan       | nan              | nan     | nan     | nan               | nan     | nan     | nan         | nan     | nan           | nan         | nan              | nan                | nan             | nan              | nan                  | nan                  | nan     | nan     | nan     | nan             |
| 6          | anshoomehra/t5-v1_1-base-squadQnliHintsMultiQgen      | nan     | 0.00      | nan            | nan       | nan                    | nan     | nan     | nan     | nan     | nan     | nan       | nan     | nan                    | nan     | nan     | nan     | nan     | nan       | nan              | nan     | nan     | nan               | nan     | nan     | nan         | nan     | nan           | nan         | nan              | nan                | nan             | nan              | nan                  | nan                  | nan     | nan     | nan     | nan             |
| 7          | anshoomehra/t5-v1_1-base-squadV2AutoQgen              | nan     | 0.00      | nan            | nan       | nan                    | nan     | nan     | nan     | nan     | nan     | nan       | nan     | nan                    | nan     | nan     | nan     | nan     | nan       | nan              | nan     | nan     | nan               | nan     | nan     | nan         | nan     | nan           | nan         | nan              | nan                | nan             | nan              | nan                  | nan                  | nan     | nan     | nan     | nan             |
| 8          | google/flan-t5-base                                   | nan     | 0.00      | nan            | nan       | nan                    | nan     | nan     | nan     | nan     | nan     | nan       | nan     | nan                    | nan     | nan     | nan     | nan     | nan       | nan              | nan     | nan     | nan               | nan     | nan     | nan         | nan     | nan           | nan         | nan              | nan                | nan             | nan              | nan                  | nan                  | nan     | nan     | nan     | nan             |


<br>
<br>
Download full models ranking table: [csv](./results/google_t5-v1_1-base_table.csv)