---
layout: default
title: Home
nav_order: 0
image: "Twitter_card.png"
description: "Model-recycling - the best model per architecture. Comparing finetuned models from HF, as base models for future finetuning. "

---
# Welcome to model-recycling page

Hardly anyone trains from scratch anymore, we all finetune over a pretrained model. 

[Research](https://arxiv.org/abs/2211.00107) slowly reaches consensus that some finetuned models are better base models than the pretrained models
themselves.

This site presents a dynamic view of the best models to choose for a given model size and architecture.
We follow the findings and methodology from our [paper](https://arxiv.org/abs/2211.00107):
We download finetuned models found in HuggingFace per architecture and efficiently rank them over a representative task.
We then evaluate the top ranked models by finetuning over a large set of 36 target tasks, and report the average
performance of each base model.

Tested so far: 2479 (and counting)
## Best models per architectures
<br>

| Pretrained                                                                   | Best model                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |   Avg. |   Pretrained Avg. | Ranking                                 |
|:-----------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------:|------------------:|:----------------------------------------|
| [roberta-base](roberta-base_pretrain_scores_table)                           | [ibm/ColD-Fusion](model_gain_chart?avg=2.25&mnli_lp=nan&20_newsgroup=0.54&ag_news=0.03&amazon_reviews_multi=-0.32&anli=1.59&boolq=2.68&cb=19.73&cola=-0.22&copa=23.30&dbpedia=1.34&esnli=0.15&financial_phrasebank=2.99&imdb=-0.04&isear=1.06&mnli=0.31&mrpc=-0.86&multirc=2.50&poem_sentiment=1.63&qnli=-0.00&qqp=0.40&rotten_tomatoes=3.41&rte=12.80&sst2=1.30&sst_5bins=-0.30&stsb=1.38&trec_coarse=-0.11&trec_fine=2.64&tweet_ev_emoji=0.00&tweet_ev_emotion=1.22&tweet_ev_hate=1.55&tweet_ev_irony=6.37&tweet_ev_offensive=1.38&tweet_ev_sentiment=-0.60&wic=3.17&wnli=-6.90&wsc=-2.69&yahoo_answers=-0.53&model_name=ibm%2FColD-Fusion&base_name=roberta-base)                                                              |  78.47 |             76.22 | [link](roberta-base_table)              |
| [bert-base-uncased](bert-base-uncased_pretrain_scores_table)                 | [ibm/ColD-Fusion-bert-base-uncased-itr23-seed0](model_gain_chart?avg=3.44&mnli_lp=nan&20_newsgroup=2.07&ag_news=-0.46&amazon_reviews_multi=0.34&anli=2.14&boolq=5.42&cb=12.41&cola=0.15&copa=8.55&dbpedia=0.04&esnli=1.02&financial_phrasebank=15.57&imdb=0.52&isear=0.22&mnli=0.65&mrpc=5.02&multirc=-0.61&poem_sentiment=18.89&qnli=-0.60&qqp=0.29&rotten_tomatoes=4.55&rte=18.00&sst2=2.18&sst_5bins=2.72&stsb=2.71&trec_coarse=1.14&trec_fine=12.67&tweet_ev_emoji=0.28&tweet_ev_emotion=1.16&tweet_ev_hate=2.20&tweet_ev_irony=0.61&tweet_ev_offensive=-0.37&tweet_ev_sentiment=0.82&wic=2.58&wnli=1.55&wsc=0.38&yahoo_answers=-1.02&model_name=ibm%2FColD-Fusion-bert-base-uncased-itr23-seed0&base_name=bert-base-uncased) |  75.64 |             72.20 | [link](bert-base-uncased_table)         |
| [bert-base-cased](bert-base-cased_pretrain_scores_table)                     | [skim945/bert-finetuned-squad](model_gain_chart?avg=2.01&mnli_lp=nan&20_newsgroup=-0.39&ag_news=0.14&amazon_reviews_multi=0.15&anli=0.31&boolq=2.43&cb=32.35&cola=-3.81&copa=-2.15&dbpedia=0.40&esnli=-0.65&financial_phrasebank=13.04&imdb=-0.31&isear=1.56&mnli=0.09&mrpc=-2.33&multirc=-2.67&poem_sentiment=6.35&qnli=1.20&qqp=0.25&rotten_tomatoes=0.07&rte=7.53&sst2=4.61&sst_5bins=-0.05&stsb=2.30&trec_coarse=-0.11&trec_fine=13.47&tweet_ev_emoji=0.06&tweet_ev_emotion=-0.09&tweet_ev_hate=0.82&tweet_ev_irony=1.77&tweet_ev_offensive=0.05&tweet_ev_sentiment=0.24&wic=5.15&wnli=0.80&wsc=-10.14&yahoo_answers=-0.13&model_name=skim945%2Fbert-finetuned-squad&base_name=bert-base-cased)                               |  74.43 |             72.43 | [link](bert-base-cased_table)           |
| [t5-base](t5-base_pretrain_scores_table)                                     | [adit94/nlpcharade](model_gain_chart?avg=2.78&mnli_lp=nan&20_newsgroup=-29.01&ag_news=2.38&amazon_reviews_multi=4.40&anli=1.58&boolq=10.84&cb=-8.92&cola=-2.62&copa=39.82&dbpedia=12.81&esnli=0.60&financial_phrasebank=1.31&imdb=-10.84&isear=26.32&mnli=8.64&mrpc=3.06&multirc=12.08&poem_sentiment=-29.04&qnli=-34.05&qqp=1.74&rotten_tomatoes=-36.72&rte=16.64&sst2=-9.88&sst_5bins=18.68&stsb=-5.99&trec_coarse=-30.77&trec_fine=-0.01&tweet_ev_emoji=47.56&tweet_ev_emotion=10.81&tweet_ev_hate=21.50&tweet_ev_irony=10.21&tweet_ev_offensive=-13.09&tweet_ev_sentiment=16.40&wic=4.61&wnli=0.99&wsc=17.17&yahoo_answers=21.01&model_name=adit94%2Fnlpcharade&base_name=t5-base)                                            |  78.23 |             75.45 | [link](t5-base_table)                   |
| [google/t5-v1_1-base](google_t5-v1_1-base_pretrain_scores_table)             | [google/flan-t5-base](model_gain_chart?avg=9.16&mnli_lp=nan&20_newsgroup=3.34&ag_news=1.49&amazon_reviews_multi=0.21&anli=13.91&boolq=16.75&cb=23.12&cola=9.97&copa=34.50&dbpedia=6.90&esnli=5.37&financial_phrasebank=18.66&imdb=0.33&isear=1.37&mnli=11.74&mrpc=16.63&multirc=6.24&poem_sentiment=14.62&qnli=3.41&qqp=6.18&rotten_tomatoes=2.98&rte=24.26&sst2=0.67&sst_5bins=5.44&stsb=20.68&trec_coarse=3.95&trec_fine=10.73&tweet_ev_emoji=13.39&tweet_ev_emotion=4.62&tweet_ev_hate=3.46&tweet_ev_irony=9.04&tweet_ev_offensive=1.69&tweet_ev_sentiment=0.75&wic=14.22&wnli=9.44&wsc=5.53&yahoo_answers=4.14&model_name=google%2Fflan-t5-base&base_name=google%2Ft5-v1_1-base)                                              |  77.98 |             68.82 | [link](google_t5-v1_1-base_table)       |
| [microsoft/deberta-v3-base](microsoft_deberta-v3-base_pretrain_scores_table) | [sileod/deberta-v3-base-tasksource-nli](model_gain_chart?avg=1.69&mnli_lp=nan&20_newsgroup=0.04&ag_news=0.22&amazon_reviews_multi=0.04&anli=1.59&boolq=2.67&cb=7.14&cola=0.58&copa=22.60&dbpedia=-0.23&esnli=-0.38&financial_phrasebank=0.72&imdb=0.18&isear=0.04&mnli=1.36&mrpc=-0.48&multirc=1.56&poem_sentiment=5.58&qnli=0.21&qqp=0.13&rotten_tomatoes=0.57&rte=8.27&sst2=0.35&sst_5bins=1.61&stsb=1.54&trec_coarse=-0.96&trec_fine=-0.22&tweet_ev_emoji=1.63&tweet_ev_emotion=1.76&tweet_ev_hate=1.26&tweet_ev_irony=3.21&tweet_ev_offensive=0.17&tweet_ev_sentiment=0.21&wic=-1.78&wnli=-2.61&wsc=2.26&yahoo_answers=0.03&model_name=sileod%2Fdeberta-v3-base-tasksource-nli&base_name=microsoft%2Fdeberta-v3-base)         |  80.73 |             79.04 | [link](microsoft_deberta-v3-base_table) |

<br>
<br>

To learn more see our [FAQ](faq) or read the paper. See detailed evaluation results on each architecture [here](Rankings).
If you have any feedback or question please [contact us](contact_us).

<span style="font-size:0.8em;">This work was performed in IBM Research by Leshem Choshen, Elad Venezian, Shachar Don-Yehiya, Noam Slonim and Yoav Katz.</span>
