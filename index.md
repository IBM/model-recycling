---
layout: default
title: Home
nav_order: 0

---
# Welcome to model-recycling page

Hardly anyone trains from scratch anymore, we all finetune over a pretrained model. Research is slowly reaches consensus that some finetuned models are better base models than the pretrained models themselves. This site presents a dynamic view of the best models to choose, given that you chose the model's size and architecture.</p>
We rank finetuned models found in HuggingFace per architecture. We efficiently check each model and test the best by full finetuning over 36 target tasks.</p>

[//]: # (Paper)

[//]: # (<a href="cite.html">Citation</a>)

[//]: # (<a href="https://github.com/IBM/model-recycling">Code</a>)

[//]: # ( <a href="faq.html">FAQ</a>)

[//]: # (</p>)

[//]: # (The <a href="roberta_absolute_scores_table.html">page</a> contains ranking of HF models.</p>)
Currently: the best RoBERTa-base models are:


[page](pretrain_scores_table.md)



