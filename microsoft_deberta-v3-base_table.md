---
layout: default
title: microsoft_deberta-v3-base
parent: Rankings
has_children: true
---
[comment]: # (This page contains a link to a table with the ranking and performance of all ranked microsoft_deberta-v3-base models. In addition, it contains a table with the baseline and the 10 best models. The original ranking was done by finetuning only the classification head of the model (linear probing) over the MNLI dataset.  The best models  by this ranking where ranked by the average accuracy after finetuning over the 36 datasets (except for the stsb dataset, where we used the Spearman correlation instead of accuracy).)

Ranking and performance of all 40 ranked microsoft_deberta-v3-base models ([full table](./results/microsoft_deberta-v3-base_table.csv)).  The top 35 models were fully tested.

Notes:
1. The baseline results can be found [here](microsoft_deberta-v3-base_pretrain_scores_table)
1. While the average improvement is small, many datasets show large gains

<br>


|            | model_name                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | avg     | mnli_lp   | 20_newsgroup   | ag_news   | amazon_reviews_multi   | anli    | boolq   | cb      | cola    | copa    | dbpedia   | esnli   | financial_phrasebank   | imdb    | isear   | mnli    | mrpc    | multirc   | poem_sentiment   | qnli    | qqp     | rotten_tomatoes   | rte     | sst2    | sst_5bins   | stsb    | trec_coarse   | trec_fine   | tweet_ev_emoji   | tweet_ev_emotion   | tweet_ev_hate   | tweet_ev_irony   | tweet_ev_offensive   | tweet_ev_sentiment   | wic     | wnli    | wsc     | yahoo_answers   |
|:-----------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------|:----------|:---------------|:----------|:-----------------------|:--------|:--------|:--------|:--------|:--------|:----------|:--------|:-----------------------|:--------|:--------|:--------|:--------|:----------|:-----------------|:--------|:--------|:------------------|:--------|:--------|:------------|:--------|:--------------|:------------|:-----------------|:-------------------|:----------------|:-----------------|:---------------------|:---------------------|:--------|:--------|:--------|:----------------|
| *baseline* | *[microsoft/deberta-v3-base](microsoft/deberta-v3-base_pretrain_scores_table)*                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | *79.04* | *nan*     | *86.41*        | *90.44*   | *66.86*                | *58.78* | *82.99* | *75.00* | *86.57* | *58.40* | *79.43*   | *91.93* | *84.48*                | *94.49* | *71.86* | *89.78* | *89.20* | *62.26*   | *86.73*          | *93.51* | *91.79* | *90.42*           | *82.35* | *95.06* | *56.98*     | *90.28* | *97.76*       | *91.02*     | *46.19*          | *83.95*            | *56.21*         | *79.82*          | *85.06*              | *71.80*              | *71.21* | *70.21* | *64.09* | *72.03*         |
| 1          | [sileod/deberta-v3-base_tasksource-420](model_gain_chart?avg=1.41&mnli_lp=nan&20_newsgroup=0.63&ag_news=0.46&amazon_reviews_multi=-0.40&anli=0.94&boolq=2.55&cb=10.71&cola=0.49&copa=10.60&dbpedia=0.10&esnli=-0.25&financial_phrasebank=1.31&imdb=-0.17&isear=0.63&mnli=0.42&mrpc=-0.23&multirc=1.73&poem_sentiment=0.77&qnli=0.12&qqp=-0.05&rotten_tomatoes=0.67&rte=2.13&sst2=0.01&sst_5bins=-0.02&stsb=1.39&trec_coarse=0.24&trec_fine=0.18&tweet_ev_emoji=0.62&tweet_ev_emotion=0.43&tweet_ev_hate=1.84&tweet_ev_irony=1.43&tweet_ev_offensive=0.17&tweet_ev_sentiment=0.08&wic=-1.78&wnli=3.03&wsc=9.95&yahoo_answers=0.17&model_name=sileod%2Fdeberta-v3-base_tasksource-420&base_name=microsoft%2Fdeberta-v3-base)                 | 80.45   | 89.82     | 87.04          | 90.90     | 66.46                  | 59.72   | 85.54   | 85.71   | 87.06   | 69.00   | 79.53     | 91.67   | 85.80                  | 94.32   | 72.49   | 90.21   | 88.97   | 63.99     | 87.50            | 93.63   | 91.74   | 91.09             | 84.48   | 95.07   | 56.97       | 91.67   | 98.00         | 91.20       | 46.81            | 84.38              | 58.05           | 81.25            | 85.23                | 71.88                | 69.44   | 73.24   | 74.04   | 72.20           |
| 2          | [mariolinml/deberta-v3-base_MNLI_10_19_v0](model_gain_chart?avg=0.71&mnli_lp=nan&20_newsgroup=-0.57&ag_news=-0.21&amazon_reviews_multi=-0.12&anli=1.28&boolq=-1.15&cb=7.14&cola=-1.72&copa=10.60&dbpedia=0.00&esnli=-0.81&financial_phrasebank=2.42&imdb=-0.12&isear=-0.48&mnli=-0.06&mrpc=-0.97&multirc=2.12&poem_sentiment=1.73&qnli=0.25&qqp=0.08&rotten_tomatoes=-0.65&rte=3.21&sst2=0.12&sst_5bins=0.48&stsb=1.46&trec_coarse=-0.16&trec_fine=0.78&tweet_ev_emoji=-0.67&tweet_ev_emotion=0.29&tweet_ev_hate=-0.22&tweet_ev_irony=0.03&tweet_ev_offensive=-0.76&tweet_ev_sentiment=-0.54&wic=-1.15&wnli=4.44&wsc=-0.63&yahoo_answers=0.10&model_name=mariolinml%2Fdeberta-v3-base_MNLI_10_19_v0&base_name=microsoft%2Fdeberta-v3-base) | 79.75   | 86.71     | 85.85          | 90.23     | 66.74                  | 60.06   | 81.83   | 82.14   | 84.85   | 69.00   | 79.43     | 91.11   | 86.90                  | 94.37   | 71.38   | 89.72   | 88.24   | 64.38     | 88.46            | 93.76   | 91.87   | 89.77             | 85.56   | 95.18   | 57.47       | 91.74   | 97.60         | 91.80       | 45.53            | 84.24              | 55.99           | 79.85            | 84.30                | 71.26                | 70.06   | 74.65   | 63.46   | 72.13           |
| 3          | [devpranjal/deberta-v3-base-devrev-data](model_gain_chart?avg=0.54&mnli_lp=nan&20_newsgroup=-0.92&ag_news=-0.51&amazon_reviews_multi=-0.14&anli=-0.59&boolq=2.27&cb=5.36&cola=-0.28&copa=11.60&dbpedia=-0.40&esnli=-0.74&financial_phrasebank=3.22&imdb=-0.48&isear=-0.61&mnli=-0.30&mrpc=0.75&multirc=1.38&poem_sentiment=-3.08&qnli=0.30&qqp=0.24&rotten_tomatoes=-0.18&rte=1.77&sst2=-0.34&sst_5bins=0.66&stsb=1.16&trec_coarse=-0.56&trec_fine=0.38&tweet_ev_emoji=0.18&tweet_ev_emotion=-0.70&tweet_ev_hate=1.46&tweet_ev_irony=-2.40&tweet_ev_offensive=0.87&tweet_ev_sentiment=-0.87&wic=-0.37&wnli=1.62&wsc=-0.63&yahoo_answers=0.47&model_name=devpranjal%2Fdeberta-v3-base-devrev-data&base_name=microsoft%2Fdeberta-v3-base)    | 79.58   | 56.73     | 85.49          | 89.93     | 66.72                  | 58.19   | 85.26   | 80.36   | 86.29   | 70.00   | 79.03     | 91.18   | 87.70                  | 94.01   | 71.25   | 89.48   | 89.95   | 63.63     | 83.65            | 93.81   | 92.03   | 90.24             | 84.12   | 94.72   | 57.65       | 91.44   | 97.20         | 91.40       | 46.37            | 83.25              | 57.68           | 77.42            | 85.93                | 70.93                | 70.85   | 71.83   | 63.46   | 72.50           |
| 4          | [nc33/deberta_finetune](model_gain_chart?avg=0.47&mnli_lp=nan&20_newsgroup=-0.22&ag_news=-0.08&amazon_reviews_multi=0.62&anli=-0.22&boolq=1.36&cb=-1.79&cola=0.01&copa=9.60&dbpedia=0.23&esnli=-0.35&financial_phrasebank=4.11&imdb=-0.02&isear=0.37&mnli=-0.15&mrpc=0.99&multirc=1.27&poem_sentiment=0.77&qnli=0.05&qqp=-0.12&rotten_tomatoes=-0.18&rte=0.69&sst2=0.12&sst_5bins=1.39&stsb=0.13&trec_coarse=-0.56&trec_fine=-0.22&tweet_ev_emoji=0.93&tweet_ev_emotion=1.13&tweet_ev_hate=3.18&tweet_ev_irony=-0.74&tweet_ev_offensive=-1.34&tweet_ev_sentiment=-1.61&wic=-0.53&wnli=-2.61&wsc=0.34&yahoo_answers=0.30&model_name=nc33%2Fdeberta_finetune&base_name=microsoft%2Fdeberta-v3-base)                                          | 79.51   | 75.33     | 86.19          | 90.37     | 67.48                  | 58.56   | 84.34   | 73.21   | 86.58   | 68.00   | 79.67     | 91.57   | 88.60                  | 94.47   | 72.23   | 89.64   | 90.20   | 63.53     | 87.50            | 93.56   | 91.67   | 90.24             | 83.03   | 95.18   | 58.37       | 90.41   | 97.20         | 90.80       | 47.12            | 85.08              | 59.39           | 79.08            | 83.72                | 70.20                | 70.69   | 67.61   | 64.42   | 72.33           |
| 5          | [nc33/finetune_rte_model](model_gain_chart?avg=0.34&mnli_lp=nan&20_newsgroup=0.56&ag_news=-0.04&amazon_reviews_multi=0.12&anli=0.59&boolq=1.57&cb=3.57&cola=0.01&copa=1.60&dbpedia=0.57&esnli=-0.80&financial_phrasebank=1.42&imdb=0.29&isear=0.63&mnli=-0.07&mrpc=-0.23&multirc=1.15&poem_sentiment=-1.15&qnli=0.10&qqp=0.34&rotten_tomatoes=0.20&rte=0.69&sst2=-0.11&sst_5bins=-1.01&stsb=1.43&trec_coarse=-0.16&trec_fine=0.18&tweet_ev_emoji=0.86&tweet_ev_emotion=-1.47&tweet_ev_hate=2.41&tweet_ev_irony=-1.51&tweet_ev_offensive=0.06&tweet_ev_sentiment=0.08&wic=0.73&wnli=0.21&wsc=-0.63&yahoo_answers=0.10&model_name=nc33%2Ffinetune_rte_model&base_name=microsoft%2Fdeberta-v3-base)                                           | 79.38   | 78.60     | 86.98          | 90.40     | 66.98                  | 59.38   | 84.56   | 78.57   | 86.58   | 60.00   | 80.00     | 91.12   | 85.90                  | 94.78   | 72.49   | 89.71   | 88.97   | 63.41     | 85.58            | 93.61   | 92.13   | 90.62             | 83.03   | 94.95   | 55.97       | 91.70   | 97.60         | 91.20       | 47.05            | 82.48              | 58.62           | 78.32            | 85.12                | 71.88                | 71.94   | 70.42   | 63.46   | 72.13           |
| 6          | [s8n29/finetuned_model_1](model_gain_chart?avg=0.21&mnli_lp=nan&20_newsgroup=-0.35&ag_news=-0.01&amazon_reviews_multi=-0.34&anli=-1.00&boolq=2.09&cb=1.79&cola=0.30&copa=13.60&dbpedia=-0.47&esnli=-1.02&financial_phrasebank=-0.98&imdb=-0.44&isear=1.08&mnli=-0.08&mrpc=0.01&multirc=1.01&poem_sentiment=-1.15&qnli=0.63&qqp=0.26&rotten_tomatoes=-0.08&rte=-2.56&sst2=-0.22&sst_5bins=0.03&stsb=0.77&trec_coarse=-0.76&trec_fine=0.18&tweet_ev_emoji=-0.72&tweet_ev_emotion=-0.77&tweet_ev_hate=1.50&tweet_ev_irony=0.92&tweet_ev_offensive=0.06&tweet_ev_sentiment=-1.84&wic=-1.15&wnli=-2.61&wsc=-0.63&yahoo_answers=0.53&model_name=s8n29%2Ffinetuned_model_1&base_name=microsoft%2Fdeberta-v3-base)                                 | 79.25   | 57.45     | 86.06          | 90.43     | 66.52                  | 57.78   | 85.08   | 76.79   | 86.86   | 72.00   | 78.97     | 90.91   | 83.50                  | 94.06   | 72.95   | 89.70   | 89.22   | 63.26     | 85.58            | 94.14   | 92.05   | 90.34             | 79.78   | 94.84   | 57.01       | 91.05   | 97.00         | 91.20       | 45.48            | 83.18              | 57.71           | 80.74            | 85.12                | 69.96                | 70.06   | 67.61   | 63.46   | 72.57           |
| 7          | [bweb771/deberta_amazon_reviews_v1](model_gain_chart?avg=0.05&mnli_lp=nan&20_newsgroup=0.32&ag_news=-0.28&amazon_reviews_multi=-0.20&anli=-2.25&boolq=2.79&cb=3.57&cola=-0.28&copa=-3.40&dbpedia=-0.20&esnli=-0.63&financial_phrasebank=0.41&imdb=-0.20&isear=-0.42&mnli=-0.32&mrpc=0.26&multirc=0.28&poem_sentiment=3.65&qnli=-0.19&qqp=-0.12&rotten_tomatoes=-1.02&rte=1.41&sst2=-1.14&sst_5bins=0.62&stsb=-0.16&trec_coarse=0.04&trec_fine=-0.62&tweet_ev_emoji=-0.68&tweet_ev_emotion=0.64&tweet_ev_hate=-0.99&tweet_ev_irony=-0.48&tweet_ev_offensive=-0.64&tweet_ev_sentiment=0.06&wic=-0.05&wnli=-1.20&wsc=3.22&yahoo_answers=0.17&model_name=bweb771%2Fdeberta_amazon_reviews_v1&base_name=microsoft%2Fdeberta-v3-base)            | 79.09   | 35.22     | 86.74          | 90.17     | 66.66                  | 56.53   | 85.78   | 78.57   | 86.29   | 55.00   | 79.23     | 91.30   | 84.90                  | 94.29   | 71.45   | 89.46   | 89.46   | 62.54     | 90.38            | 93.32   | 91.66   | 89.40             | 83.75   | 93.92   | 57.60       | 90.12   | 97.80         | 90.40       | 45.51            | 84.59              | 55.22           | 79.34            | 84.42                | 71.87                | 71.16   | 69.01   | 67.31   | 72.20           |
| 8          | [AI-Ahmed/deberta-v3-base-funetuned-cls-qqa](model_gain_chart?avg=0.04&mnli_lp=nan&20_newsgroup=-0.71&ag_news=0.16&amazon_reviews_multi=0.36&anli=-0.00&boolq=0.22&cb=5.36&cola=0.20&copa=5.60&dbpedia=0.07&esnli=-0.72&financial_phrasebank=-2.48&imdb=-0.22&isear=0.69&mnli=0.24&mrpc=-0.72&multirc=0.45&poem_sentiment=-3.08&qnli=0.30&qqp=0.03&rotten_tomatoes=0.01&rte=-1.48&sst2=0.01&sst_5bins=1.30&stsb=1.38&trec_coarse=-0.76&trec_fine=0.18&tweet_ev_emoji=1.13&tweet_ev_emotion=-0.21&tweet_ev_hate=4.73&tweet_ev_irony=-1.63&tweet_ev_offensive=0.29&tweet_ev_sentiment=0.40&wic=-1.47&wnli=-5.42&wsc=-2.55&yahoo_answers=-0.07&model_name=AI-Ahmed%2Fdeberta-v3-base-funetuned-cls-qqa&base_name=microsoft%2Fdeberta-v3-base) | 79.08   | 75.66     | 85.70          | 90.60     | 67.22                  | 58.78   | 83.21   | 80.36   | 86.77   | 64.00   | 79.50     | 91.21   | 82.00                  | 94.27   | 72.56   | 90.02   | 88.48   | 62.71     | 83.65            | 93.81   | 91.82   | 90.43             | 80.87   | 95.07   | 58.28       | 91.65   | 97.00         | 91.20       | 47.32            | 83.74              | 60.94           | 78.19            | 85.35                | 72.20                | 69.75   | 64.79   | 61.54   | 71.97           |
| 9          | [deepset/deberta-v3-base-squad2](model_gain_chart?avg=0.04&mnli_lp=nan&20_newsgroup=-0.26&ag_news=-0.51&amazon_reviews_multi=0.10&anli=-1.25&boolq=2.46&cb=3.57&cola=-0.47&copa=13.60&dbpedia=0.10&esnli=-0.74&financial_phrasebank=-0.28&imdb=-0.34&isear=0.23&mnli=-0.22&mrpc=0.75&multirc=1.09&poem_sentiment=-3.08&qnli=0.36&qqp=0.04&rotten_tomatoes=-0.18&rte=1.05&sst2=-0.34&sst_5bins=1.93&stsb=1.16&trec_coarse=-0.56&trec_fine=0.38&tweet_ev_emoji=0.18&tweet_ev_emotion=-0.70&tweet_ev_hate=-0.49&tweet_ev_irony=-2.27&tweet_ev_offensive=-12.97&tweet_ev_sentiment=-0.87&wic=-0.37&wnli=1.62&wsc=-0.63&yahoo_answers=-0.60&model_name=deepset%2Fdeberta-v3-base-squad2&base_name=microsoft%2Fdeberta-v3-base)                  | 79.08   | 56.73     | 86.15          | 89.93     | 66.96                  | 57.53   | 85.44   | 78.57   | 86.10   | 72.00   | 79.53     | 91.18   | 84.20                  | 94.15   | 72.10   | 89.56   | 89.95   | 63.35     | 83.65            | 93.87   | 91.83   | 90.24             | 83.39   | 94.72   | 58.91       | 91.44   | 97.20         | 91.40       | 46.37            | 83.25              | 55.72           | 77.55            | 72.09                | 70.93                | 70.85   | 71.83   | 63.46   | 71.43           |
| 10         | [nc33/qna2_deberta_model](model_gain_chart?avg=0.04&mnli_lp=nan&20_newsgroup=-0.65&ag_news=-0.48&amazon_reviews_multi=-0.32&anli=0.13&boolq=0.59&cb=7.14&cola=1.45&copa=10.60&dbpedia=0.37&esnli=-1.09&financial_phrasebank=0.81&imdb=0.10&isear=-0.03&mnli=0.04&mrpc=-1.21&multirc=1.31&poem_sentiment=1.73&qnli=0.01&qqp=0.15&rotten_tomatoes=-1.02&rte=-2.56&sst2=0.01&sst_5bins=-1.19&stsb=0.76&trec_coarse=-0.16&trec_fine=-1.22&tweet_ev_emoji=-1.60&tweet_ev_emotion=0.50&tweet_ev_hate=-3.72&tweet_ev_irony=0.28&tweet_ev_offensive=0.29&tweet_ev_sentiment=-0.92&wic=-0.21&wnli=-8.24&wsc=-0.63&yahoo_answers=0.43&model_name=nc33%2Fqna2_deberta_model&base_name=microsoft%2Fdeberta-v3-base)                                    | 79.08   | 72.40     | 85.77          | 89.97     | 66.54                  | 58.91   | 83.58   | 82.14   | 88.02   | 69.00   | 79.80     | 90.84   | 85.30                  | 94.59   | 71.84   | 89.82   | 87.99   | 63.57     | 88.46            | 93.52   | 91.94   | 89.40             | 79.78   | 95.07   | 55.79       | 91.04   | 97.60         | 89.80       | 44.59            | 84.45              | 52.49           | 80.10            | 85.35                | 70.88                | 71.00   | 61.97   | 63.46   | 72.47           |


<br>
<br>
Download full models ranking table: [csv](./results/microsoft_deberta-v3-base_table.csv)

[Home](.)