---
layout: default
title: microsoft_deberta-v3-base
parent: Rankings
has_children: true
---
[comment]: # (This page contains a link to a table with the ranking and performance of all ranked microsoft_deberta-v3-base models. In addition, it contains a table with the baseline and the 10 best models. The original ranking was done by finetuning only the classification head of the model (linear probing) over the MNLI dataset.  The best models  by this ranking where ranked by the average accuracy after finetuning over the 36 datasets (except for the stsb dataset, where we used the Spearman correlation instead of accuracy).)

Ranking and performance of all 20 ranked microsoft_deberta-v3-base models ([full table](./results/microsoft_deberta-v3-base_table.csv)).  The top 15 models were fully tested.

Notes:
1. The baseline results can be found [here](microsoft_deberta-v3-base_pretrain_scores_table)
1. While the average improvement is small, many datasets show large gains

<br>


|            | model_name                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | avg     | mnli_lp   | 20_newsgroup   | ag_news   | amazon_reviews_multi   | anli    | boolq   | cb      | cola    | copa    | dbpedia   | esnli   | financial_phrasebank   | imdb    | isear   | mnli    | mrpc    | multirc   | poem_sentiment   | qnli    | qqp     | rotten_tomatoes   | rte     | sst2    | sst_5bins   | stsb    | trec_coarse   | trec_fine   | tweet_ev_emoji   | tweet_ev_emotion   | tweet_ev_hate   | tweet_ev_irony   | tweet_ev_offensive   | tweet_ev_sentiment   | wic     | wnli    | wsc     | yahoo_answers   |
|:-----------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------|:----------|:---------------|:----------|:-----------------------|:--------|:--------|:--------|:--------|:--------|:----------|:--------|:-----------------------|:--------|:--------|:--------|:--------|:----------|:-----------------|:--------|:--------|:------------------|:--------|:--------|:------------|:--------|:--------------|:------------|:-----------------|:-------------------|:----------------|:-----------------|:---------------------|:---------------------|:--------|:--------|:--------|:----------------|
| *baseline* | *[microsoft/deberta-v3-base](microsoft/deberta-v3-base_pretrain_scores_table)*                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | *79.04* | *nan*     | *86.41*        | *90.44*   | *66.86*                | *58.78* | *82.99* | *75.00* | *86.57* | *58.40* | *79.43*   | *91.93* | *84.48*                | *94.49* | *71.86* | *89.78* | *89.20* | *62.26*   | *86.73*          | *93.51* | *91.79* | *90.42*           | *82.35* | *95.06* | *56.98*     | *90.28* | *97.76*       | *91.02*     | *46.19*          | *83.95*            | *56.21*         | *79.82*          | *85.06*              | *71.80*              | *71.21* | *70.21* | *64.09* | *72.03*         |
| 1          | [sileod/deberta-v3-base_tasksource-420](model_gain_chart?avg=1.41&mnli_lp=nan&20_newsgroup=0.63&ag_news=0.46&amazon_reviews_multi=-0.40&anli=0.94&boolq=2.55&cb=10.71&cola=0.49&copa=10.60&dbpedia=0.10&esnli=-0.25&financial_phrasebank=1.31&imdb=-0.17&isear=0.63&mnli=0.42&mrpc=-0.23&multirc=1.73&poem_sentiment=0.77&qnli=0.12&qqp=-0.05&rotten_tomatoes=0.67&rte=2.13&sst2=0.01&sst_5bins=-0.02&stsb=1.39&trec_coarse=0.24&trec_fine=0.18&tweet_ev_emoji=0.62&tweet_ev_emotion=0.43&tweet_ev_hate=1.84&tweet_ev_irony=1.43&tweet_ev_offensive=0.17&tweet_ev_sentiment=0.08&wic=-1.78&wnli=3.03&wsc=9.95&yahoo_answers=0.17&model_name=sileod%2Fdeberta-v3-base_tasksource-420&base_name=microsoft%2Fdeberta-v3-base)                             | 80.45   | 89.82     | 87.04          | 90.90     | 66.46                  | 59.72   | 85.54   | 85.71   | 87.06   | 69.00   | 79.53     | 91.67   | 85.80                  | 94.32   | 72.49   | 90.21   | 88.97   | 63.99     | 87.50            | 93.63   | 91.74   | 91.09             | 84.48   | 95.07   | 56.97       | 91.67   | 98.00         | 91.20       | 46.81            | 84.38              | 58.05           | 81.25            | 85.23                | 71.88                | 69.44   | 73.24   | 74.04   | 72.20           |
| 2          | [MoritzLaurer/DeBERTa-v3-base-mnli](model_gain_chart?avg=0.97&mnli_lp=nan&20_newsgroup=-0.39&ag_news=0.19&amazon_reviews_multi=0.10&anli=1.31&boolq=0.81&cb=8.93&cola=0.01&copa=13.60&dbpedia=-0.23&esnli=-0.51&financial_phrasebank=0.61&imdb=-0.26&isear=-0.35&mnli=-0.34&mrpc=1.24&multirc=1.50&poem_sentiment=-0.19&qnli=0.30&qqp=0.13&rotten_tomatoes=-0.55&rte=3.57&sst2=0.35&sst_5bins=0.39&stsb=1.10&trec_coarse=-0.36&trec_fine=-0.02&tweet_ev_emoji=1.11&tweet_ev_emotion=-0.35&tweet_ev_hate=1.43&tweet_ev_irony=-2.65&tweet_ev_offensive=-1.69&tweet_ev_sentiment=-1.51&wic=0.57&wnli=-2.61&wsc=9.95&yahoo_answers=-0.33&model_name=MoritzLaurer%2FDeBERTa-v3-base-mnli&base_name=microsoft%2Fdeberta-v3-base)                             | 80.01   | 0.00      | 86.02          | 90.63     | 66.96                  | 60.09   | 83.79   | 83.93   | 86.58   | 72.00   | 79.20     | 91.42   | 85.10                  | 94.23   | 71.51   | 89.44   | 90.44   | 63.76     | 86.54            | 93.81   | 91.91   | 89.87             | 85.92   | 95.41   | 57.38       | 91.38   | 97.40         | 91.00       | 47.30            | 83.60              | 57.64           | 77.17            | 83.37                | 70.29                | 71.79   | 67.61   | 74.04   | 71.70           |
| 3          | [MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli](model_gain_chart?avg=0.65&mnli_lp=nan&20_newsgroup=-0.61&ag_news=-0.01&amazon_reviews_multi=0.46&anli=0.84&boolq=2.12&cb=16.07&cola=-0.76&copa=8.60&dbpedia=-0.40&esnli=-0.29&financial_phrasebank=-1.98&imdb=-0.47&isear=-0.22&mnli=-0.21&mrpc=0.50&multirc=1.91&poem_sentiment=1.73&qnli=0.07&qqp=-0.37&rotten_tomatoes=-0.74&rte=3.94&sst2=-0.45&sst_5bins=0.07&stsb=1.27&trec_coarse=-0.16&trec_fine=0.18&tweet_ev_emoji=-0.93&tweet_ev_emotion=-1.33&tweet_ev_hate=-1.67&tweet_ev_irony=-5.46&tweet_ev_offensive=-0.17&tweet_ev_sentiment=-0.11&wic=-0.21&wnli=-1.20&wsc=4.18&yahoo_answers=-0.70&model_name=MoritzLaurer%2FDeBERTa-v3-base-mnli-fever-anli&base_name=microsoft%2Fdeberta-v3-base) | 79.69   | 0.00      | 85.81          | 90.43     | 67.32                  | 59.62   | 85.11   | 91.07   | 85.81   | 67.00   | 79.03     | 91.63   | 82.50                  | 94.02   | 71.64   | 89.57   | 89.71   | 64.17     | 88.46            | 93.57   | 91.41   | 89.68             | 86.28   | 94.61   | 57.06       | 91.55   | 97.60         | 91.20       | 45.26            | 82.62              | 54.55           | 74.36            | 84.88                | 71.69                | 71.00   | 69.01   | 68.27   | 71.33           |
| 4          | [nc33/finetune_rte_model](model_gain_chart?avg=0.34&mnli_lp=nan&20_newsgroup=0.56&ag_news=-0.04&amazon_reviews_multi=0.12&anli=0.59&boolq=1.57&cb=3.57&cola=0.01&copa=1.60&dbpedia=0.57&esnli=-0.80&financial_phrasebank=1.42&imdb=0.29&isear=0.63&mnli=-0.07&mrpc=-0.23&multirc=1.15&poem_sentiment=-1.15&qnli=0.10&qqp=0.34&rotten_tomatoes=0.20&rte=0.69&sst2=-0.11&sst_5bins=-1.01&stsb=1.43&trec_coarse=-0.16&trec_fine=0.18&tweet_ev_emoji=0.86&tweet_ev_emotion=-1.47&tweet_ev_hate=2.41&tweet_ev_irony=-1.51&tweet_ev_offensive=0.06&tweet_ev_sentiment=0.08&wic=0.73&wnli=0.21&wsc=-0.63&yahoo_answers=0.10&model_name=nc33%2Ffinetune_rte_model&base_name=microsoft%2Fdeberta-v3-base)                                                       | 79.38   | 78.60     | 86.98          | 90.40     | 66.98                  | 59.38   | 84.56   | 78.57   | 86.58   | 60.00   | 80.00     | 91.12   | 85.90                  | 94.78   | 72.49   | 89.71   | 88.97   | 63.41     | 85.58            | 93.61   | 92.13   | 90.62             | 83.03   | 94.95   | 55.97       | 91.70   | 97.60         | 91.20       | 47.05            | 82.48              | 58.62           | 78.32            | 85.12                | 71.88                | 71.94   | 70.42   | 63.46   | 72.13           |
| 5          | [SetFit/deberta-v3-base__sst2__all-train](model_gain_chart?avg=0.10&mnli_lp=nan&20_newsgroup=0.06&ag_news=0.36&amazon_reviews_multi=0.08&anli=0.63&boolq=1.45&cb=3.57&cola=0.39&copa=-1.40&dbpedia=0.57&esnli=-0.53&financial_phrasebank=1.52&imdb=-0.04&isear=-0.22&mnli=-0.19&mrpc=0.99&multirc=2.00&poem_sentiment=0.77&qnli=-0.19&qqp=0.21&rotten_tomatoes=-0.18&rte=-0.76&sst2=-0.34&sst_5bins=-0.60&stsb=-0.32&trec_coarse=0.24&trec_fine=-0.22&tweet_ev_emoji=0.82&tweet_ev_emotion=0.50&tweet_ev_hate=-3.92&tweet_ev_irony=-0.99&tweet_ev_offensive=-0.17&tweet_ev_sentiment=-0.96&wic=1.20&wnli=-2.61&wsc=2.26&yahoo_answers=-0.27&model_name=SetFit%2Fdeberta-v3-base__sst2__all-train&base_name=microsoft%2Fdeberta-v3-base)                | 79.14   | 0.00      | 86.47          | 90.80     | 66.94                  | 59.41   | 84.43   | 78.57   | 86.96   | 57.00   | 80.00     | 91.40   | 86.00                  | 94.45   | 71.64   | 89.60   | 90.20   | 64.25     | 87.50            | 93.32   | 91.99   | 90.24             | 81.59   | 94.72   | 56.38       | 89.96   | 98.00         | 90.80       | 47.01            | 84.45              | 52.29           | 78.83            | 84.88                | 70.84                | 72.41   | 67.61   | 66.35   | 71.77           |
| 6          | [bweb771/deberta_amazon_reviews_v1](model_gain_chart?avg=0.05&mnli_lp=nan&20_newsgroup=0.32&ag_news=-0.28&amazon_reviews_multi=-0.20&anli=-2.25&boolq=2.79&cb=3.57&cola=-0.28&copa=-3.40&dbpedia=-0.20&esnli=-0.63&financial_phrasebank=0.41&imdb=-0.20&isear=-0.42&mnli=-0.32&mrpc=0.26&multirc=0.28&poem_sentiment=3.65&qnli=-0.19&qqp=-0.12&rotten_tomatoes=-1.02&rte=1.41&sst2=-1.14&sst_5bins=0.62&stsb=-0.16&trec_coarse=0.04&trec_fine=-0.62&tweet_ev_emoji=-0.68&tweet_ev_emotion=0.64&tweet_ev_hate=-0.99&tweet_ev_irony=-0.48&tweet_ev_offensive=-0.64&tweet_ev_sentiment=0.06&wic=-0.05&wnli=-1.20&wsc=3.22&yahoo_answers=0.17&model_name=bweb771%2Fdeberta_amazon_reviews_v1&base_name=microsoft%2Fdeberta-v3-base)                        | 79.09   | 35.22     | 86.74          | 90.17     | 66.66                  | 56.53   | 85.78   | 78.57   | 86.29   | 55.00   | 79.23     | 91.30   | 84.90                  | 94.29   | 71.45   | 89.46   | 89.46   | 62.54     | 90.38            | 93.32   | 91.66   | 89.40             | 83.75   | 93.92   | 57.60       | 90.12   | 97.80         | 90.40       | 45.51            | 84.59              | 55.22           | 79.34            | 84.42                | 71.87                | 71.16   | 69.01   | 67.31   | 72.20           |
| 7          | [deepset/deberta-v3-base-squad2](model_gain_chart?avg=0.04&mnli_lp=nan&20_newsgroup=-0.26&ag_news=-0.51&amazon_reviews_multi=0.10&anli=-1.25&boolq=2.46&cb=3.57&cola=-0.47&copa=13.60&dbpedia=0.10&esnli=-0.74&financial_phrasebank=-0.28&imdb=-0.34&isear=0.23&mnli=-0.22&mrpc=0.75&multirc=1.09&poem_sentiment=-3.08&qnli=0.36&qqp=0.04&rotten_tomatoes=-0.18&rte=1.05&sst2=-0.34&sst_5bins=1.93&stsb=1.16&trec_coarse=-0.56&trec_fine=0.38&tweet_ev_emoji=0.18&tweet_ev_emotion=-0.70&tweet_ev_hate=-0.49&tweet_ev_irony=-2.27&tweet_ev_offensive=-12.97&tweet_ev_sentiment=-0.87&wic=-0.37&wnli=1.62&wsc=-0.63&yahoo_answers=-0.60&model_name=deepset%2Fdeberta-v3-base-squad2&base_name=microsoft%2Fdeberta-v3-base)                              | 79.08   | 56.73     | 86.15          | 89.93     | 66.96                  | 57.53   | 85.44   | 78.57   | 86.10   | 72.00   | 79.53     | 91.18   | 84.20                  | 94.15   | 72.10   | 89.56   | 89.95   | 63.35     | 83.65            | 93.87   | 91.83   | 90.24             | 83.39   | 94.72   | 58.91       | 91.44   | 97.20         | 91.40       | 46.37            | 83.25              | 55.72           | 77.55            | 72.09                | 70.93                | 70.85   | 71.83   | 63.46   | 71.43           |
| 8          | [nc33/qna2_deberta_model](model_gain_chart?avg=0.04&mnli_lp=nan&20_newsgroup=-0.65&ag_news=-0.48&amazon_reviews_multi=-0.32&anli=0.13&boolq=0.59&cb=7.14&cola=1.45&copa=10.60&dbpedia=0.37&esnli=-1.09&financial_phrasebank=0.81&imdb=0.10&isear=-0.03&mnli=0.04&mrpc=-1.21&multirc=1.31&poem_sentiment=1.73&qnli=0.01&qqp=0.15&rotten_tomatoes=-1.02&rte=-2.56&sst2=0.01&sst_5bins=-1.19&stsb=0.76&trec_coarse=-0.16&trec_fine=-1.22&tweet_ev_emoji=-1.60&tweet_ev_emotion=0.50&tweet_ev_hate=-3.72&tweet_ev_irony=0.28&tweet_ev_offensive=0.29&tweet_ev_sentiment=-0.92&wic=-0.21&wnli=-8.24&wsc=-0.63&yahoo_answers=0.43&model_name=nc33%2Fqna2_deberta_model&base_name=microsoft%2Fdeberta-v3-base)                                                | 79.08   | 72.40     | 85.77          | 89.97     | 66.54                  | 58.91   | 83.58   | 82.14   | 88.02   | 69.00   | 79.80     | 90.84   | 85.30                  | 94.59   | 71.84   | 89.82   | 87.99   | 63.57     | 88.46            | 93.52   | 91.94   | 89.40             | 79.78   | 95.07   | 55.79       | 91.04   | 97.60         | 89.80       | 44.59            | 84.45              | 52.49           | 80.10            | 85.35                | 70.88                | 71.00   | 61.97   | 63.46   | 72.47           |
| 9          | [nc33/3label_model](model_gain_chart?avg=-0.35&mnli_lp=nan&20_newsgroup=-0.18&ag_news=0.36&amazon_reviews_multi=0.48&anli=0.44&boolq=1.78&cb=0.00&cola=0.68&copa=-3.40&dbpedia=0.80&esnli=-0.56&financial_phrasebank=1.42&imdb=0.03&isear=-0.22&mnli=-0.00&mrpc=-0.97&multirc=1.19&poem_sentiment=-1.15&qnli=-0.15&qqp=0.06&rotten_tomatoes=0.01&rte=-1.12&sst2=-0.34&sst_5bins=-3.27&stsb=0.30&trec_coarse=0.24&trec_fine=-0.82&tweet_ev_emoji=0.93&tweet_ev_emotion=-0.07&tweet_ev_hate=0.05&tweet_ev_irony=-1.12&tweet_ev_offensive=0.29&tweet_ev_sentiment=-0.33&wic=-1.15&wnli=0.21&wsc=-6.39&yahoo_answers=-0.60&model_name=nc33%2F3label_model&base_name=microsoft%2Fdeberta-v3-base)                                                           | 78.69   | 70.66     | 86.23          | 90.80     | 67.34                  | 59.22   | 84.77   | 75.00   | 87.25   | 55.00   | 80.23     | 91.37   | 85.90                  | 94.52   | 71.64   | 89.78   | 88.24   | 63.45     | 85.58            | 93.36   | 91.85   | 90.43             | 81.23   | 94.72   | 53.71       | 90.58   | 98.00         | 90.20       | 47.12            | 83.88              | 56.26           | 78.70            | 85.35                | 71.48                | 70.06   | 70.42   | 57.69   | 71.43           |
| 10         | [ItuThesis2022MlviNikw/deberta-v3-base](model_gain_chart?avg=-1.40&mnli_lp=nan&20_newsgroup=-0.47&ag_news=0.16&amazon_reviews_multi=0.08&anli=-0.31&boolq=-0.75&cb=0.00&cola=0.78&copa=-3.40&dbpedia=-0.33&esnli=-0.76&financial_phrasebank=2.11&imdb=-0.04&isear=1.08&mnli=0.03&mrpc=-1.46&multirc=1.65&poem_sentiment=-0.19&qnli=-0.35&qqp=-0.39&rotten_tomatoes=0.29&rte=-3.29&sst2=0.58&sst_5bins=-1.24&stsb=0.38&trec_coarse=-0.36&trec_fine=-0.42&tweet_ev_emoji=0.68&tweet_ev_emotion=-0.70&tweet_ev_hate=1.09&tweet_ev_irony=-9.67&tweet_ev_offensive=0.52&tweet_ev_sentiment=-0.89&wic=0.26&wnli=-30.77&wsc=-4.47&yahoo_answers=0.33&model_name=ItuThesis2022MlviNikw%2Fdeberta-v3-base&base_name=microsoft%2Fdeberta-v3-base)                | 77.64   | 0.00      | 85.94          | 90.60     | 66.94                  | 58.47   | 82.23   | 75.00   | 87.34   | 55.00   | 79.10     | 91.16   | 86.60                  | 94.45   | 72.95   | 89.81   | 87.75   | 63.90     | 86.54            | 93.15   | 91.40   | 90.71             | 79.06   | 95.64   | 55.75       | 90.66   | 97.40         | 90.60       | 46.87            | 83.25              | 57.31           | 70.15            | 85.58                | 70.91                | 71.47   | 39.44   | 59.62   | 72.37           |


<br>
<br>
Download full models ranking table: [csv](./results/microsoft_deberta-v3-base_table.csv)

[Home](.)