---
layout: default
title: microsoft_deberta-v3-base
parent: Rankings
has_children: true
---
[comment]: # (This page contains a link to a table with the ranking and performance of all ranked microsoft_deberta-v3-base models. In addition, it contains a table with the baseline and the 10 best models. The original ranking was done by finetuning only the classification head of the model (linear probing) over the MNLI dataset.  The best models  by this ranking where ranked by the average accuracy after finetuning over the 36 datasets (except for the stsb dataset, where we used the Spearman correlation instead of accuracy).)

Ranking and performance of all 61 ranked microsoft_deberta-v3-base models ([full table](./results/microsoft_deberta-v3-base_table.csv)).  The top 55 models were fully tested.

Notes:
1. The baseline results can be found [here](microsoft_deberta-v3-base_pretrain_scores_table)
1. While the average improvement is small, many datasets show large gains

<br>


|            | model_name                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | avg     | mnli_lp   | 20_newsgroup   | ag_news   | amazon_reviews_multi   | anli    | boolq   | cb      | cola    | copa    | dbpedia   | esnli   | financial_phrasebank   | imdb    | isear   | mnli    | mrpc    | multirc   | poem_sentiment   | qnli    | qqp     | rotten_tomatoes   | rte     | sst2    | sst_5bins   | stsb    | trec_coarse   | trec_fine   | tweet_ev_emoji   | tweet_ev_emotion   | tweet_ev_hate   | tweet_ev_irony   | tweet_ev_offensive   | tweet_ev_sentiment   | wic     | wnli    | wsc     | yahoo_answers   |
|:-----------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------|:----------|:---------------|:----------|:-----------------------|:--------|:--------|:--------|:--------|:--------|:----------|:--------|:-----------------------|:--------|:--------|:--------|:--------|:----------|:-----------------|:--------|:--------|:------------------|:--------|:--------|:------------|:--------|:--------------|:------------|:-----------------|:-------------------|:----------------|:-----------------|:---------------------|:---------------------|:--------|:--------|:--------|:----------------|
| *baseline* | *[microsoft/deberta-v3-base](microsoft/deberta-v3-base_pretrain_scores_table)*                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | *79.04* | *nan*     | *86.41*        | *90.44*   | *66.86*                | *58.78* | *82.99* | *75.00* | *86.57* | *58.40* | *79.43*   | *91.93* | *84.48*                | *94.49* | *71.86* | *89.78* | *89.20* | *62.26*   | *86.73*          | *93.51* | *91.79* | *90.42*           | *82.35* | *95.06* | *56.98*     | *90.28* | *97.76*       | *91.02*     | *46.19*          | *83.95*            | *56.21*         | *79.82*          | *85.06*              | *71.80*              | *71.21* | *70.21* | *64.09* | *72.03*         |
| 1          | [sileod/deberta-v3-base-tasksource-nli](model_gain_chart?avg=1.69&mnli_lp=nan&20_newsgroup=0.04&ag_news=0.22&amazon_reviews_multi=0.04&anli=1.59&boolq=2.67&cb=7.14&cola=0.58&copa=22.60&dbpedia=-0.23&esnli=-0.38&financial_phrasebank=0.72&imdb=0.18&isear=0.04&mnli=1.36&mrpc=-0.48&multirc=1.56&poem_sentiment=5.58&qnli=0.21&qqp=0.13&rotten_tomatoes=0.57&rte=8.27&sst2=0.35&sst_5bins=1.61&stsb=1.54&trec_coarse=-0.96&trec_fine=-0.22&tweet_ev_emoji=1.63&tweet_ev_emotion=1.76&tweet_ev_hate=1.26&tweet_ev_irony=3.21&tweet_ev_offensive=0.17&tweet_ev_sentiment=0.21&wic=-1.78&wnli=-2.61&wsc=2.26&yahoo_answers=0.03&model_name=sileod%2Fdeberta-v3-base-tasksource-nli&base_name=microsoft%2Fdeberta-v3-base)                    | 80.73   | 93.73     | 86.46          | 90.67     | 66.90                  | 60.38   | 85.66   | 82.14   | 87.15   | 81.00   | 79.20     | 91.54   | 85.20                  | 94.67   | 71.90   | 91.14   | 88.73   | 63.82     | 92.31            | 93.72   | 91.92   | 90.99             | 90.61   | 95.41   | 58.60       | 91.81   | 96.80         | 90.80       | 47.82            | 85.71              | 57.47           | 83.04            | 85.23                | 72.01                | 69.44   | 67.61   | 66.35   | 72.07           |
| 2          | [sileod/deberta-v3-base_tasksource-420](model_gain_chart?avg=1.41&mnli_lp=nan&20_newsgroup=0.63&ag_news=0.46&amazon_reviews_multi=-0.40&anli=0.94&boolq=2.55&cb=10.71&cola=0.49&copa=10.60&dbpedia=0.10&esnli=-0.25&financial_phrasebank=1.31&imdb=-0.17&isear=0.63&mnli=0.42&mrpc=-0.23&multirc=1.73&poem_sentiment=0.77&qnli=0.12&qqp=-0.05&rotten_tomatoes=0.67&rte=2.13&sst2=0.01&sst_5bins=-0.02&stsb=1.39&trec_coarse=0.24&trec_fine=0.18&tweet_ev_emoji=0.62&tweet_ev_emotion=0.43&tweet_ev_hate=1.84&tweet_ev_irony=1.43&tweet_ev_offensive=0.17&tweet_ev_sentiment=0.08&wic=-1.78&wnli=3.03&wsc=9.95&yahoo_answers=0.17&model_name=sileod%2Fdeberta-v3-base_tasksource-420&base_name=microsoft%2Fdeberta-v3-base)                   | 80.45   | 89.82     | 87.04          | 90.90     | 66.46                  | 59.72   | 85.54   | 85.71   | 87.06   | 69.00   | 79.53     | 91.67   | 85.80                  | 94.32   | 72.49   | 90.21   | 88.97   | 63.99     | 87.50            | 93.63   | 91.74   | 91.09             | 84.48   | 95.07   | 56.97       | 91.67   | 98.00         | 91.20       | 46.81            | 84.38              | 58.05           | 81.25            | 85.23                | 71.88                | 69.44   | 73.24   | 74.04   | 72.20           |
| 3          | [mariolinml/deberta-v3-base_MNLI_10_19_v0](model_gain_chart?avg=0.71&mnli_lp=nan&20_newsgroup=-0.57&ag_news=-0.21&amazon_reviews_multi=-0.12&anli=1.28&boolq=-1.15&cb=7.14&cola=-1.72&copa=10.60&dbpedia=0.00&esnli=-0.81&financial_phrasebank=2.42&imdb=-0.12&isear=-0.48&mnli=-0.06&mrpc=-0.97&multirc=2.12&poem_sentiment=1.73&qnli=0.25&qqp=0.08&rotten_tomatoes=-0.65&rte=3.21&sst2=0.12&sst_5bins=0.48&stsb=1.46&trec_coarse=-0.16&trec_fine=0.78&tweet_ev_emoji=-0.67&tweet_ev_emotion=0.29&tweet_ev_hate=-0.22&tweet_ev_irony=0.03&tweet_ev_offensive=-0.76&tweet_ev_sentiment=-0.54&wic=-1.15&wnli=4.44&wsc=-0.63&yahoo_answers=0.10&model_name=mariolinml%2Fdeberta-v3-base_MNLI_10_19_v0&base_name=microsoft%2Fdeberta-v3-base)   | 79.75   | 86.71     | 85.85          | 90.23     | 66.74                  | 60.06   | 81.83   | 82.14   | 84.85   | 69.00   | 79.43     | 91.11   | 86.90                  | 94.37   | 71.38   | 89.72   | 88.24   | 64.38     | 88.46            | 93.76   | 91.87   | 89.77             | 85.56   | 95.18   | 57.47       | 91.74   | 97.60         | 91.80       | 45.53            | 84.24              | 55.99           | 79.85            | 84.30                | 71.26                | 70.06   | 74.65   | 63.46   | 72.13           |
| 4          | [devpranjal/deberta-v3-base-devrev-data](model_gain_chart?avg=0.54&mnli_lp=nan&20_newsgroup=-0.92&ag_news=-0.51&amazon_reviews_multi=-0.14&anli=-0.59&boolq=2.27&cb=5.36&cola=-0.28&copa=11.60&dbpedia=-0.40&esnli=-0.74&financial_phrasebank=3.22&imdb=-0.48&isear=-0.61&mnli=-0.30&mrpc=0.75&multirc=1.38&poem_sentiment=-3.08&qnli=0.30&qqp=0.24&rotten_tomatoes=-0.18&rte=1.77&sst2=-0.34&sst_5bins=0.66&stsb=1.16&trec_coarse=-0.56&trec_fine=0.38&tweet_ev_emoji=0.18&tweet_ev_emotion=-0.70&tweet_ev_hate=1.46&tweet_ev_irony=-2.40&tweet_ev_offensive=0.87&tweet_ev_sentiment=-0.87&wic=-0.37&wnli=1.62&wsc=-0.63&yahoo_answers=0.47&model_name=devpranjal%2Fdeberta-v3-base-devrev-data&base_name=microsoft%2Fdeberta-v3-base)      | 79.58   | 56.73     | 85.49          | 89.93     | 66.72                  | 58.19   | 85.26   | 80.36   | 86.29   | 70.00   | 79.03     | 91.18   | 87.70                  | 94.01   | 71.25   | 89.48   | 89.95   | 63.63     | 83.65            | 93.81   | 92.03   | 90.24             | 84.12   | 94.72   | 57.65       | 91.44   | 97.20         | 91.40       | 46.37            | 83.25              | 57.68           | 77.42            | 85.93                | 70.93                | 70.85   | 71.83   | 63.46   | 72.50           |
| 5          | [nc33/deberta_finetune](model_gain_chart?avg=0.47&mnli_lp=nan&20_newsgroup=-0.22&ag_news=-0.08&amazon_reviews_multi=0.62&anli=-0.22&boolq=1.36&cb=-1.79&cola=0.01&copa=9.60&dbpedia=0.23&esnli=-0.35&financial_phrasebank=4.11&imdb=-0.02&isear=0.37&mnli=-0.15&mrpc=0.99&multirc=1.27&poem_sentiment=0.77&qnli=0.05&qqp=-0.12&rotten_tomatoes=-0.18&rte=0.69&sst2=0.12&sst_5bins=1.39&stsb=0.13&trec_coarse=-0.56&trec_fine=-0.22&tweet_ev_emoji=0.93&tweet_ev_emotion=1.13&tweet_ev_hate=3.18&tweet_ev_irony=-0.74&tweet_ev_offensive=-1.34&tweet_ev_sentiment=-1.61&wic=-0.53&wnli=-2.61&wsc=0.34&yahoo_answers=0.30&model_name=nc33%2Fdeberta_finetune&base_name=microsoft%2Fdeberta-v3-base)                                            | 79.51   | 75.33     | 86.19          | 90.37     | 67.48                  | 58.56   | 84.34   | 73.21   | 86.58   | 68.00   | 79.67     | 91.57   | 88.60                  | 94.47   | 72.23   | 89.64   | 90.20   | 63.53     | 87.50            | 93.56   | 91.67   | 90.24             | 83.03   | 95.18   | 58.37       | 90.41   | 97.20         | 90.80       | 47.12            | 85.08              | 59.39           | 79.08            | 83.72                | 70.20                | 70.69   | 67.61   | 64.42   | 72.33           |
| 6          | [nc33/finetune_rte_model](model_gain_chart?avg=0.34&mnli_lp=nan&20_newsgroup=0.56&ag_news=-0.04&amazon_reviews_multi=0.12&anli=0.59&boolq=1.57&cb=3.57&cola=0.01&copa=1.60&dbpedia=0.57&esnli=-0.80&financial_phrasebank=1.42&imdb=0.29&isear=0.63&mnli=-0.07&mrpc=-0.23&multirc=1.15&poem_sentiment=-1.15&qnli=0.10&qqp=0.34&rotten_tomatoes=0.20&rte=0.69&sst2=-0.11&sst_5bins=-1.01&stsb=1.43&trec_coarse=-0.16&trec_fine=0.18&tweet_ev_emoji=0.86&tweet_ev_emotion=-1.47&tweet_ev_hate=2.41&tweet_ev_irony=-1.51&tweet_ev_offensive=0.06&tweet_ev_sentiment=0.08&wic=0.73&wnli=0.21&wsc=-0.63&yahoo_answers=0.10&model_name=nc33%2Ffinetune_rte_model&base_name=microsoft%2Fdeberta-v3-base)                                             | 79.38   | 78.60     | 86.98          | 90.40     | 66.98                  | 59.38   | 84.56   | 78.57   | 86.58   | 60.00   | 80.00     | 91.12   | 85.90                  | 94.78   | 72.49   | 89.71   | 88.97   | 63.41     | 85.58            | 93.61   | 92.13   | 90.62             | 83.03   | 94.95   | 55.97       | 91.70   | 97.60         | 91.20       | 47.05            | 82.48              | 58.62           | 78.32            | 85.12                | 71.88                | 71.94   | 70.42   | 63.46   | 72.13           |
| 7          | [s8n29/finetuned_model_1](model_gain_chart?avg=0.21&mnli_lp=nan&20_newsgroup=-0.35&ag_news=-0.01&amazon_reviews_multi=-0.34&anli=-1.00&boolq=2.09&cb=1.79&cola=0.30&copa=13.60&dbpedia=-0.47&esnli=-1.02&financial_phrasebank=-0.98&imdb=-0.44&isear=1.08&mnli=-0.08&mrpc=0.01&multirc=1.01&poem_sentiment=-1.15&qnli=0.63&qqp=0.26&rotten_tomatoes=-0.08&rte=-2.56&sst2=-0.22&sst_5bins=0.03&stsb=0.77&trec_coarse=-0.76&trec_fine=0.18&tweet_ev_emoji=-0.72&tweet_ev_emotion=-0.77&tweet_ev_hate=1.50&tweet_ev_irony=0.92&tweet_ev_offensive=0.06&tweet_ev_sentiment=-1.84&wic=-1.15&wnli=-2.61&wsc=-0.63&yahoo_answers=0.53&model_name=s8n29%2Ffinetuned_model_1&base_name=microsoft%2Fdeberta-v3-base)                                   | 79.25   | 57.45     | 86.06          | 90.43     | 66.52                  | 57.78   | 85.08   | 76.79   | 86.86   | 72.00   | 78.97     | 90.91   | 83.50                  | 94.06   | 72.95   | 89.70   | 89.22   | 63.26     | 85.58            | 94.14   | 92.05   | 90.34             | 79.78   | 94.84   | 57.01       | 91.05   | 97.00         | 91.20       | 45.48            | 83.18              | 57.71           | 80.74            | 85.12                | 69.96                | 70.06   | 67.61   | 63.46   | 72.57           |
| 8          | [koolerkx/autotrain-sns-fake-news-3229590413](model_gain_chart?avg=0.21&mnli_lp=nan&20_newsgroup=0.36&ag_news=0.62&amazon_reviews_multi=0.12&anli=1.66&boolq=2.15&cb=0.00&cola=-0.37&copa=-6.40&dbpedia=0.00&esnli=-1.03&financial_phrasebank=1.81&imdb=-0.10&isear=0.43&mnli=-0.42&mrpc=0.01&multirc=0.22&poem_sentiment=2.69&qnli=0.18&qqp=0.25&rotten_tomatoes=0.29&rte=-1.12&sst2=-0.22&sst_5bins=1.75&stsb=0.92&trec_coarse=-0.96&trec_fine=0.78&tweet_ev_emoji=0.74&tweet_ev_emotion=-0.28&tweet_ev_hate=-1.43&tweet_ev_irony=-0.74&tweet_ev_offensive=-0.06&tweet_ev_sentiment=-0.20&wic=0.73&wnli=5.85&wsc=-0.63&yahoo_answers=-0.20&model_name=koolerkx%2Fautotrain-sns-fake-news-3229590413&base_name=microsoft%2Fdeberta-v3-base) | 79.24   | 65.50     | 86.78          | 91.07     | 66.98                  | 60.44   | 85.14   | 75.00   | 86.19   | 52.00   | 79.43     | 90.90   | 86.30                  | 94.39   | 72.29   | 89.36   | 89.22   | 62.48     | 89.42            | 93.68   | 92.04   | 90.71             | 81.23   | 94.84   | 58.73       | 91.20   | 96.80         | 91.80       | 46.93            | 83.67              | 54.78           | 79.08            | 85.00                | 71.61                | 71.94   | 76.06   | 63.46   | 71.83           |
| 9          | [nc33/test_glue](model_gain_chart?avg=0.14&mnli_lp=nan&20_newsgroup=0.04&ag_news=-0.48&amazon_reviews_multi=0.02&anli=1.31&boolq=0.62&cb=7.14&cola=1.45&copa=10.60&dbpedia=0.37&esnli=-1.09&financial_phrasebank=0.81&imdb=0.02&isear=-0.03&mnli=0.02&mrpc=-1.21&multirc=2.04&poem_sentiment=1.73&qnli=-0.50&qqp=0.17&rotten_tomatoes=0.85&rte=-2.56&sst2=0.12&sst_5bins=-1.19&stsb=0.76&trec_coarse=-0.16&trec_fine=-1.22&tweet_ev_emoji=-0.74&tweet_ev_emotion=0.50&tweet_ev_hate=-3.72&tweet_ev_irony=0.28&tweet_ev_offensive=-0.87&tweet_ev_sentiment=-1.49&wic=-0.21&wnli=-8.24&wsc=-0.63&yahoo_answers=0.43&model_name=nc33%2Ftest_glue&base_name=microsoft%2Fdeberta-v3-base)                                                         | 79.18   | 72.40     | 86.46          | 89.97     | 66.88                  | 60.09   | 83.61   | 82.14   | 88.02   | 69.00   | 79.80     | 90.84   | 85.30                  | 94.51   | 71.84   | 89.80   | 87.99   | 64.29     | 88.46            | 93.01   | 91.95   | 91.28             | 79.78   | 95.18   | 55.79       | 91.04   | 97.60         | 89.80       | 45.45            | 84.45              | 52.49           | 80.10            | 84.19                | 70.32                | 71.00   | 61.97   | 63.46   | 72.47           |
| 10         | [bweb771/deberta_amazon_reviews_v1](model_gain_chart?avg=0.05&mnli_lp=nan&20_newsgroup=0.32&ag_news=-0.28&amazon_reviews_multi=-0.20&anli=-2.25&boolq=2.79&cb=3.57&cola=-0.28&copa=-3.40&dbpedia=-0.20&esnli=-0.63&financial_phrasebank=0.41&imdb=-0.20&isear=-0.42&mnli=-0.32&mrpc=0.26&multirc=0.28&poem_sentiment=3.65&qnli=-0.19&qqp=-0.12&rotten_tomatoes=-1.02&rte=1.41&sst2=-1.14&sst_5bins=0.62&stsb=-0.16&trec_coarse=0.04&trec_fine=-0.62&tweet_ev_emoji=-0.68&tweet_ev_emotion=0.64&tweet_ev_hate=-0.99&tweet_ev_irony=-0.48&tweet_ev_offensive=-0.64&tweet_ev_sentiment=0.06&wic=-0.05&wnli=-1.20&wsc=3.22&yahoo_answers=0.17&model_name=bweb771%2Fdeberta_amazon_reviews_v1&base_name=microsoft%2Fdeberta-v3-base)              | 79.09   | 35.22     | 86.74          | 90.17     | 66.66                  | 56.53   | 85.78   | 78.57   | 86.29   | 55.00   | 79.23     | 91.30   | 84.90                  | 94.29   | 71.45   | 89.46   | 89.46   | 62.54     | 90.38            | 93.32   | 91.66   | 89.40             | 83.75   | 93.92   | 57.60       | 90.12   | 97.80         | 90.40       | 45.51            | 84.59              | 55.22           | 79.34            | 84.42                | 71.87                | 71.16   | 69.01   | 67.31   | 72.20           |


<br>
<br>
Download full models ranking table: [csv](./results/microsoft_deberta-v3-base_table.csv)

[Home](.)