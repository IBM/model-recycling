---
layout: default
title: roberta-base
parent: Rankings
has_children: true
---
[comment]: # (This page contains a link to a table with the ranking and performance of all ranked roberta-base models. In addition, it contains a table with the baseline and the 10 best models. The original ranking was done by finetuning only the classification head of the model (linear probing) over the MNLI dataset.  The best models  by this ranking where ranked by the average accuracy after finetuning over the 36 datasets (except for the stsb dataset, where we used the Spearman correlation instead of accuracy).)

Ranking and performance of all 1269 ranked roberta-base models ([full table](./results/roberta-base_table.csv)).  The top 386 models were fully tested.

Notes:
1. The baseline results can be found [here](roberta-base_pretrain_scores_table)
1. While the average improvement is small, many datasets show large gains
1. [ColD Fusion](https://arxiv.org/abs/2212.01378) variations were removed to avoid cluttering the table
<br>


|            | model_name                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | avg     | mnli_lp   | 20_newsgroup   | ag_news   | amazon_reviews_multi   | anli    | boolq   | cb      | cola    | copa    | dbpedia   | esnli   | financial_phrasebank   | imdb    | isear   | mnli    | mrpc    | multirc   | poem_sentiment   | qnli    | qqp     | rotten_tomatoes   | rte     | sst2    | sst_5bins   | stsb    | trec_coarse   | trec_fine   | tweet_ev_emoji   | tweet_ev_emotion   | tweet_ev_hate   | tweet_ev_irony   | tweet_ev_offensive   | tweet_ev_sentiment   | wic     | wnli    | wsc     | yahoo_answers   |
|:-----------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------|:----------|:---------------|:----------|:-----------------------|:--------|:--------|:--------|:--------|:--------|:----------|:--------|:-----------------------|:--------|:--------|:--------|:--------|:----------|:-----------------|:--------|:--------|:------------------|:--------|:--------|:------------|:--------|:--------------|:------------|:-----------------|:-------------------|:----------------|:-----------------|:---------------------|:---------------------|:--------|:--------|:--------|:----------------|
| *baseline* | *[roberta-base](roberta-base_pretrain_scores_table)*                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | *76.22* | *nan*     | *85.28*        | *89.77*   | *66.58*                | *50.35* | *78.69* | *67.77* | *83.53* | *48.70* | *77.30*   | *90.99* | *85.11*                | *93.90* | *72.47* | *86.98* | *87.87* | *61.22*   | *83.94*          | *92.41* | *90.71* | *88.42*           | *72.40* | *94.12* | *56.68*     | *89.92* | *97.11*       | *87.76*     | *46.30*          | *81.82*            | *52.89*         | *71.56*          | *84.55*              | *71.03*              | *65.48* | *54.79* | *63.27* | *72.40*         |
| 1          | [ibm/ColD-Fusion](model_gain_chart?avg=2.25&mnli_lp=nan&20_newsgroup=0.54&ag_news=0.03&amazon_reviews_multi=-0.32&anli=1.59&boolq=2.68&cb=19.73&cola=-0.22&copa=23.30&dbpedia=1.34&esnli=0.15&financial_phrasebank=2.99&imdb=-0.04&isear=1.06&mnli=0.31&mrpc=-0.86&multirc=2.50&poem_sentiment=1.63&qnli=-0.00&qqp=0.40&rotten_tomatoes=3.41&rte=12.80&sst2=1.30&sst_5bins=-0.30&stsb=1.38&trec_coarse=-0.11&trec_fine=2.64&tweet_ev_emoji=0.00&tweet_ev_emotion=1.22&tweet_ev_hate=1.55&tweet_ev_irony=6.37&tweet_ev_offensive=1.38&tweet_ev_sentiment=-0.60&wic=3.17&wnli=-6.90&wsc=-2.69&yahoo_answers=-0.53&model_name=ibm%2FColD-Fusion&base_name=roberta-base)                                                                              | 78.47   | 86.09     | 85.82          | 89.80     | 66.26                  | 51.94   | 81.38   | 87.50   | 83.32   | 72.00   | 78.63     | 91.14   | 88.10                  | 93.86   | 73.53   | 87.30   | 87.01   | 63.72     | 85.58            | 92.40   | 91.11   | 91.84             | 85.20   | 95.41   | 56.38       | 91.30   | 97.00         | 90.40       | 46.31            | 83.04              | 54.44           | 77.93            | 85.93                | 70.43                | 68.65   | 47.89   | 60.58   | 71.87           |
| 2          | [gustavecortal/roberta_emo](model_gain_chart?avg=2.24&mnli_lp=nan&20_newsgroup=0.54&ag_news=0.46&amazon_reviews_multi=-0.50&anli=1.81&boolq=2.93&cb=21.52&cola=-0.12&copa=22.30&dbpedia=0.20&esnli=-0.30&financial_phrasebank=0.99&imdb=-0.12&isear=0.54&mnli=-0.16&mrpc=0.37&multirc=2.85&poem_sentiment=4.52&qnli=0.47&qqp=0.24&rotten_tomatoes=2.95&rte=10.99&sst2=1.64&sst_5bins=0.79&stsb=1.59&trec_coarse=0.09&trec_fine=3.44&tweet_ev_emoji=-0.31&tweet_ev_emotion=0.65&tweet_ev_hate=-0.40&tweet_ev_irony=4.08&tweet_ev_offensive=2.08&tweet_ev_sentiment=-0.16&wic=3.02&wnli=-8.31&wsc=0.19&yahoo_answers=-0.14&model_name=gustavecortal%2Froberta_emo&base_name=roberta-base)                                                           | 78.47   | 84.87     | 85.82          | 90.23     | 66.08                  | 52.16   | 81.62   | 89.29   | 83.41   | 71.00   | 77.50     | 90.70   | 86.10                  | 93.78   | 73.01   | 86.82   | 88.24   | 64.07     | 88.46            | 92.88   | 90.95   | 91.37             | 83.39   | 95.76   | 57.47       | 91.51   | 97.20         | 91.20       | 45.99            | 82.48              | 52.49           | 75.64            | 86.63                | 70.87                | 68.50   | 46.48   | 63.46   | 72.27           |
| 3          | [jakub014/ColD-Fusion-finetuned-convincingness-acl2016](model_gain_chart?avg=2.17&mnli_lp=nan&20_newsgroup=0.84&ag_news=-0.60&amazon_reviews_multi=0.10&anli=1.87&boolq=2.74&cb=17.95&cola=-0.70&copa=18.30&dbpedia=0.47&esnli=0.11&financial_phrasebank=0.49&imdb=-0.34&isear=-0.63&mnli=0.55&mrpc=-0.37&multirc=2.81&poem_sentiment=7.40&qnli=0.80&qqp=0.57&rotten_tomatoes=3.51&rte=13.88&sst2=1.30&sst_5bins=1.60&stsb=1.42&trec_coarse=0.09&trec_fine=1.04&tweet_ev_emoji=0.18&tweet_ev_emotion=1.64&tweet_ev_hate=2.06&tweet_ev_irony=2.42&tweet_ev_offensive=1.38&tweet_ev_sentiment=-0.15&wic=1.45&wnli=-5.49&wsc=-0.77&yahoo_answers=0.10&model_name=jakub014%2FColD-Fusion-finetuned-convincingness-acl2016&base_name=roberta-base)     | 78.39   | 84.05     | 86.13          | 89.17     | 66.68                  | 52.22   | 81.44   | 85.71   | 82.84   | 67.00   | 77.77     | 91.10   | 85.60                  | 93.56   | 71.84   | 87.53   | 87.50   | 64.03     | 91.35            | 93.21   | 91.28   | 91.93             | 86.28   | 95.41   | 58.28       | 91.34   | 97.20         | 88.80       | 46.49            | 83.46              | 54.95           | 73.98            | 85.93                | 70.88                | 66.93   | 49.30   | 62.50   | 72.50           |
| 4          | [jakub014/ColD-Fusion-finetuned-convincingness-IBM](model_gain_chart?avg=2.14&mnli_lp=nan&20_newsgroup=0.70&ag_news=-0.40&amazon_reviews_multi=0.68&anli=0.97&boolq=2.87&cb=21.52&cola=-0.70&copa=26.30&dbpedia=-0.30&esnli=0.26&financial_phrasebank=2.49&imdb=0.28&isear=-0.05&mnli=0.24&mrpc=1.35&multirc=2.95&poem_sentiment=4.52&qnli=-0.19&qqp=0.19&rotten_tomatoes=3.04&rte=12.80&sst2=1.41&sst_5bins=0.97&stsb=1.60&trec_coarse=0.29&trec_fine=-0.36&tweet_ev_emoji=-0.06&tweet_ev_emotion=1.01&tweet_ev_hate=1.11&tweet_ev_irony=3.95&tweet_ev_offensive=0.68&tweet_ev_sentiment=-1.18&wic=1.29&wnli=-6.90&wsc=-5.58&yahoo_answers=-0.80&model_name=jakub014%2FColD-Fusion-finetuned-convincingness-IBM&base_name=roberta-base)          | 78.36   | 85.08     | 85.98          | 89.37     | 67.26                  | 51.31   | 81.56   | 89.29   | 82.84   | 75.00   | 77.00     | 91.26   | 87.60                  | 94.18   | 72.43   | 87.23   | 89.22   | 64.17     | 88.46            | 92.22   | 90.90   | 91.46             | 85.20   | 95.53   | 57.65       | 91.52   | 97.40         | 87.40       | 46.24            | 82.83              | 54.01           | 75.51            | 85.23                | 69.85                | 66.77   | 47.89   | 57.69   | 71.60           |
| 5          | [janeel/muppet-roberta-base-finetuned-squad](model_gain_chart?avg=1.81&mnli_lp=nan&20_newsgroup=-0.39&ag_news=-0.10&amazon_reviews_multi=0.58&anli=3.25&boolq=3.69&cb=14.38&cola=-1.65&copa=13.30&dbpedia=0.47&esnli=0.34&financial_phrasebank=0.49&imdb=0.22&isear=0.48&mnli=-0.43&mrpc=1.59&multirc=3.04&poem_sentiment=3.56&qnli=0.29&qqp=0.29&rotten_tomatoes=2.29&rte=11.35&sst2=1.87&sst_5bins=1.47&stsb=1.38&trec_coarse=-0.11&trec_fine=2.84&tweet_ev_emoji=0.16&tweet_ev_emotion=0.37&tweet_ev_hate=1.48&tweet_ev_irony=8.54&tweet_ev_offensive=0.33&tweet_ev_sentiment=0.82&wic=4.74&wnli=-15.35&wsc=0.19&yahoo_answers=-0.47&model_name=janeel%2Fmuppet-roberta-base-finetuned-squad&base_name=roberta-base)                           | 78.04   | 83.24     | 84.89          | 89.67     | 67.16                  | 53.59   | 82.39   | 82.14   | 81.88   | 62.00   | 77.77     | 91.34   | 85.60                  | 94.12   | 72.95   | 86.55   | 89.46   | 64.25     | 87.50            | 92.70   | 91.00   | 90.71             | 83.75   | 95.99   | 58.14       | 91.29   | 97.00         | 90.60       | 46.46            | 82.20              | 54.38           | 80.10            | 84.88                | 71.85                | 70.22   | 39.44   | 63.46   | 71.93           |
| 6          | [mwong/roberta-base-climate-evidence-related](model_gain_chart?avg=0.98&mnli_lp=nan&20_newsgroup=-0.15&ag_news=0.16&amazon_reviews_multi=-0.04&anli=-0.13&boolq=-6.29&cb=9.93&cola=-0.31&copa=35.90&dbpedia=0.41&esnli=-1.35&financial_phrasebank=-0.51&imdb=0.09&isear=0.67&mnli=0.14&mrpc=2.09&multirc=25.91&poem_sentiment=-0.29&qnli=-0.11&qqp=-0.78&rotten_tomatoes=0.51&rte=-0.20&sst2=0.95&sst_5bins=-1.97&stsb=-16.78&trec_coarse=-0.31&trec_fine=-0.36&tweet_ev_emoji=0.27&tweet_ev_emotion=-0.40&tweet_ev_hate=-1.24&tweet_ev_irony=-0.13&tweet_ev_offensive=0.56&tweet_ev_sentiment=-0.69&wic=-10.55&wnli=0.14&wsc=0.19&yahoo_answers=-0.00&model_name=mwong%2Froberta-base-climate-evidence-related&base_name=roberta-base)           | 77.21   | 55.09     | 85.13          | 89.93     | 66.54                  | 50.22   | 72.40   | 77.70   | 83.22   | 84.60   | 77.70     | 89.65   | 84.60                  | 93.99   | 73.14   | 87.12   | 89.96   | 87.12     | 83.65            | 92.29   | 89.93   | 88.93             | 72.20   | 95.07   | 54.71       | 73.14   | 96.80         | 87.40       | 46.57            | 81.42              | 51.65           | 71.43            | 85.12                | 70.34                | 54.93   | 54.93   | 63.46   | 72.40           |
| 7          | [k4black/roberta-base-e-snli-classification-nli-base](model_gain_chart?avg=0.83&mnli_lp=nan&20_newsgroup=0.14&ag_news=-0.47&amazon_reviews_multi=-0.04&anli=1.31&boolq=1.18&cb=10.80&cola=-0.22&copa=10.30&dbpedia=0.00&esnli=-0.30&financial_phrasebank=1.09&imdb=0.06&isear=0.74&mnli=-0.18&mrpc=-2.08&multirc=0.87&poem_sentiment=-2.21&qnli=-0.06&qqp=0.33&rotten_tomatoes=-0.34&rte=7.74&sst2=0.26&sst_5bins=-0.21&stsb=1.05&trec_coarse=0.69&trec_fine=-0.16&tweet_ev_emoji=0.10&tweet_ev_emotion=-0.40&tweet_ev_hate=-0.07&tweet_ev_irony=-2.68&tweet_ev_offensive=-0.95&tweet_ev_sentiment=-1.67&wic=4.27&wnli=1.55&wsc=0.19&yahoo_answers=-0.64&model_name=k4black%2Froberta-base-e-snli-classification-nli-base&base_name=roberta-base) | 77.06   | 80.54     | 85.42          | 89.30     | 66.54                  | 51.66   | 79.88   | 78.57   | 83.32   | 59.00   | 77.30     | 90.70   | 86.20                  | 93.96   | 73.21   | 86.80   | 85.78   | 62.09     | 81.73            | 92.35   | 91.04   | 88.09             | 80.14   | 94.38   | 56.47       | 90.97   | 97.80         | 87.60       | 46.40            | 81.42              | 52.83           | 68.88            | 83.60                | 69.36                | 69.75   | 56.34   | 63.46   | 71.77           |
| 8          | [facebook/muppet-roberta-base](model_gain_chart?avg=0.78&mnli_lp=nan&20_newsgroup=4.72&ag_news=-0.00&amazon_reviews_multi=19.92&anli=2.25&boolq=3.48&cb=12.59&cola=-2.33&copa=16.30&dbpedia=7.87&esnli=-38.40&financial_phrasebank=-39.01&imdb=-2.16&isear=0.54&mnli=6.06&mrpc=1.10&multirc=2.93&poem_sentiment=10.19&qnli=-7.93&qqp=0.54&rotten_tomatoes=-30.32&rte=-32.96&sst2=-27.06&sst_5bins=38.16&stsb=1.66&trec_coarse=-11.53&trec_fine=9.04&tweet_ev_emoji=36.45&tweet_ev_emotion=-30.71&tweet_ev_hate=23.13&tweet_ev_irony=13.20&tweet_ev_offensive=-12.98&tweet_ev_sentiment=16.04&wic=1.14&wnli=36.31&wsc=0.19&yahoo_answers=-0.50&model_name=facebook%2Fmuppet-roberta-base&base_name=roberta-base)                                   | 77.00   | 84.75     | 90.00          | 89.77     | 86.50                  | 52.59   | 82.17   | 80.36   | 81.21   | 65.00   | 85.17     | 52.59   | 46.10                  | 91.74   | 73.01   | 93.04   | 88.97   | 64.15     | 94.14            | 84.48   | 91.25   | 58.10             | 39.44   | 67.06   | 94.84       | 91.58   | 85.58         | 96.80       | 82.76            | 51.11              | 76.02           | 84.77            | 71.57                | 87.07                | 66.61   | 91.10   | 63.46   | 71.90           |
| 9          | [WillHeld/roberta-base-mnli](model_gain_chart?avg=0.70&mnli_lp=nan&20_newsgroup=-1.80&ag_news=0.30&amazon_reviews_multi=17.92&anli=0.40&boolq=1.49&cb=14.38&cola=-2.90&copa=23.30&dbpedia=0.14&esnli=-40.24&financial_phrasebank=-39.46&imdb=-0.92&isear=-2.13&mnli=4.78&mrpc=0.61&multirc=1.59&poem_sentiment=-2.21&qnli=-9.74&qqp=0.49&rotten_tomatoes=-2.21&rte=-14.65&sst2=-28.28&sst_5bins=37.47&stsb=-0.10&trec_coarse=-1.11&trec_fine=-2.76&tweet_ev_emoji=32.30&tweet_ev_emotion=-29.67&tweet_ev_hate=17.26&tweet_ev_irony=12.04&tweet_ev_offensive=-14.32&tweet_ev_sentiment=15.95&wic=1.29&wnli=35.07&wsc=2.12&yahoo_answers=-1.14&model_name=WillHeld%2Froberta-base-mnli&base_name=roberta-base)                                      | 76.93   | 86.22     | 83.48          | 90.07     | 84.50                  | 50.75   | 80.18   | 82.14   | 80.63   | 72.00   | 77.43     | 50.75   | 45.65                  | 92.98   | 70.34   | 91.76   | 88.48   | 62.81     | 81.73            | 82.67   | 91.20   | 86.21             | 57.75   | 65.84   | 94.15       | 89.82   | 96.00         | 85.00       | 78.61            | 52.15              | 70.15           | 83.60            | 70.23                | 86.98                | 66.77   | 89.86   | 65.38   | 71.27           |
| 10         | [deepakvk/roberta-base-squad2-finetuned-squad](model_gain_chart?avg=0.67&mnli_lp=nan&20_newsgroup=0.13&ag_news=-0.40&amazon_reviews_multi=0.04&anli=1.87&boolq=0.42&cb=1.88&cola=-0.79&copa=6.30&dbpedia=0.31&esnli=-0.35&financial_phrasebank=3.69&imdb=-0.47&isear=-0.63&mnli=-0.49&mrpc=0.37&multirc=2.29&poem_sentiment=1.63&qnli=0.43&qqp=-0.02&rotten_tomatoes=-0.90&rte=4.86&sst2=-1.00&sst_5bins=-0.07&stsb=0.18&trec_coarse=0.69&trec_fine=1.24&tweet_ev_emoji=-0.70&tweet_ev_emotion=-0.68&tweet_ev_hate=0.61&tweet_ev_irony=-0.01&tweet_ev_offensive=-0.72&tweet_ev_sentiment=-1.02&wic=4.11&wnli=1.55&wsc=0.19&yahoo_answers=-0.40&model_name=deepakvk%2Froberta-base-squad2-finetuned-squad&base_name=roberta-base)                  | 76.89   | 61.13     | 85.41          | 89.37     | 66.62                  | 52.22   | 79.11   | 69.64   | 82.74   | 55.00   | 77.60     | 90.65   | 88.80                  | 93.43   | 71.84   | 86.49   | 88.24   | 63.51     | 85.58            | 92.84   | 90.69   | 87.52             | 77.26   | 93.12   | 56.61       | 90.09   | 97.80         | 89.00       | 45.60            | 81.14              | 53.50           | 71.56            | 83.84                | 70.01                | 69.59   | 56.34   | 63.46   | 72.00           |


<br>
<br>
Download full models ranking table: [csv](./results/roberta-base_table.csv)

[Home](.)