---
layout: default
title: t5-base
parent: Rankings
has_children: true
---
[comment]: # (This page contains a link to a table with the ranking and performance of all ranked t5-base models. In addition, it contains a table with the baseline and the 10 best models. The original ranking was done by finetuning only the classification head of the model (linear probing) over the MNLI dataset.  The best models  by this ranking where ranked by the average accuracy after finetuning over the 36 datasets (except for the stsb dataset, where we used the Spearman correlation instead of accuracy).)

Ranking and performance of all ranked t5-base models ([full table](./results/t5-base_table.csv)).

Notes:
1. Changes of more than 0.36 above the [STD](t5-base-Baseline) are considered significant
1. While the average improvement is small, many datasets show large gains.
1. Muppet based model trained on many of the datasets, and may hence show
<br>


|            | model_name                            | avg     | mnli_lp   | 20_newsgroup   | ag_news   | amazon_reviews_multi   | anli    | boolq   | cb      | cola    | copa    | dbpedia   | esnli   | financial_phrasebank   | imdb    | isear   | mnli    | mrpc    | multirc   | poem_sentiment   | qnli    | qqp     | rotten_tomatoes   | rte     | sst2    | sst_5bins   | stsb    | trec_coarse   | trec_fine   | tweet_ev_emoji   | tweet_ev_emotion   | tweet_ev_hate   | tweet_ev_irony   | tweet_ev_offensive   | tweet_ev_sentiment   | wic     | wnli    | wsc     | yahoo_answers   |
|:-----------|:--------------------------------------|:--------|:----------|:---------------|:----------|:-----------------------|:--------|:--------|:--------|:--------|:--------|:----------|:--------|:-----------------------|:--------|:--------|:--------|:--------|:----------|:-----------------|:--------|:--------|:------------------|:--------|:--------|:------------|:--------|:--------------|:------------|:-----------------|:-------------------|:----------------|:-----------------|:---------------------|:---------------------|:--------|:--------|:--------|:----------------|
| *baseline* | *t5-base*                             | *76.22* | *nan*     | *85.28*        | *89.77*   | *66.58*                | *50.35* | *78.69* | *67.77* | *83.53* | *48.70* | *77.30*   | *90.99* | *85.11*                | *93.90* | *72.47* | *86.98* | *87.87* | *61.22*   | *83.94*          | *92.41* | *90.71* | *88.42*           | *72.40* | *94.12* | *56.68*     | *89.92* | *97.11*       | *87.76*     | *46.30*          | *81.82*            | *52.89*         | *71.56*          | *84.55*              | *71.03*              | *65.48* | *54.79* | *63.27* | *72.40*         |
| 1          | Muzzi/t5-base-finetuned-eli5          | 76.08   | 82.60     | 88.65          | 92.80     | 84.88                  | nan     | 69.91   | 64.42   | 81.69   | 71.77   | 92.80     | 49.28   | 70.43                  | 85.10   | 98.00   | 92.77   | 86.76   | 70.40     | 66.76            | 74.73   | 90.76   | 44.00             | 56.34   | 54.21   | 81.49       | 61.08   | 93.92         | 54.57       | 86.71            | 92.77              | 74.73           | 56.34            | 90.52                | 49.28                | 77.00   | 90.52   | 85.75   | 81.73           |
| 2          | din0s/t5-base-asqa-ob                 | 75.50   | 82.45     | 97.80          | 71.07     | 45.66                  | nan     | 48.00   | 61.12   | 81.30   | 67.71   | 92.60     | 49.03   | 52.22                  | 55.66   | 76.37   | 56.34   | 87.25   | 57.69     | 88.65            | 90.45   | 90.52   | 93.12             | 49.03   | 83.30   | 66.98       | 78.65   | 92.37         | 83.65       | 76.02            | 84.42              | 71.24           | 86.56            | 92.51                | 77.26                | 89.20   | 90.45   | 72.10   | 86.17           |
| 3          | din0s/t5-base-asqa-cb                 | 75.45   | 81.91     | 91.00          | 71.51     | 86.40                  | nan     | 80.36   | 42.00   | 81.21   | 61.61   | 86.09     | 47.72   | 46.48                  | 88.37   | 72.23   | 77.98   | 89.71   | 70.38     | 92.70            | 54.93   | 90.74   | 54.30             | 90.66   | 66.18   | 93.69       | 79.72   | 88.46         | 97.60       | 81.98            | 51.72              | 85.23           | 70.46            | 87.01                | 92.81                | 54.81   | 47.72   | 88.90   | 77.97           |
| 4          | theojolliffe/T5-model-1-feedback-0510 | 75.30   | 82.04     | 92.40          | 72.49     | 84.40                  | nan     | 89.29   | 52.00   | 81.50   | 57.49   | 86.40     | 49.59   | 45.30                  | 89.21   | 72.03   | 92.77   | 85.05   | 65.52     | 92.69            | 78.34   | 90.97   | 55.70             | 54.93   | 67.44   | 93.35       | 79.14   | 85.58         | 97.80       | 80.51            | 53.50              | 78.06           | 85.12            | 69.53                | 86.59                | 55.77   | 49.59   | 89.23   | 76.23           |
| 5          | helliun/conversational-qgen           | nan     | 81.89     | nan            | nan       | nan                    | nan     | nan     | nan     | nan     | nan     | nan       | nan     | nan                    | nan     | nan     | nan     | nan     | nan       | nan              | nan     | nan     | nan               | nan     | nan     | nan         | nan     | nan           | nan         | nan              | nan                | nan             | nan              | nan                  | nan                  | nan     | nan     | nan     | nan             |
| 6          | din0s/t5-base-msmarco-nlgen-ob        | nan     | 81.84     | nan            | nan       | nan                    | nan     | nan     | nan     | nan     | nan     | nan       | nan     | nan                    | nan     | nan     | nan     | nan     | nan       | nan              | nan     | nan     | nan               | nan     | nan     | nan         | nan     | nan           | nan         | nan              | nan                | nan             | nan              | nan                  | nan                  | nan     | nan     | nan     | nan             |
| 7          | din0s/t5-base-msmarco-nlgen-cb        | nan     | 81.54     | nan            | nan       | nan                    | nan     | nan     | nan     | nan     | nan     | nan       | nan     | nan                    | nan     | nan     | nan     | nan     | nan       | nan              | nan     | nan     | nan               | nan     | nan     | nan         | nan     | nan           | nan         | nan              | nan                | nan             | nan              | nan                  | nan                  | nan     | nan     | nan     | nan             |
| 8          | KES/ENG-TEC                           | nan     | 81.08     | nan            | nan       | nan                    | nan     | nan     | nan     | nan     | nan     | nan       | nan     | nan                    | nan     | nan     | nan     | nan     | nan       | nan              | nan     | nan     | nan               | nan     | nan     | nan         | nan     | nan           | nan         | nan              | nan                | nan             | nan              | nan                  | nan                  | nan     | nan     | nan     | nan             |
| 9          | Ghani-25/predy                        | nan     | 0.00      | nan            | nan       | nan                    | nan     | nan     | nan     | nan     | nan     | nan       | nan     | nan                    | nan     | nan     | nan     | nan     | nan       | nan              | nan     | nan     | nan               | nan     | nan     | nan         | nan     | nan           | nan         | nan              | nan                | nan             | nan              | nan                  | nan                  | nan     | nan     | nan     | nan             |
| 10         | din0s/t5-base-eli5-ob                 | nan     | 0.00      | nan            | nan       | nan                    | nan     | nan     | nan     | nan     | nan     | nan       | nan     | nan                    | nan     | nan     | nan     | nan     | nan       | nan              | nan     | nan     | nan               | nan     | nan     | nan         | nan     | nan           | nan         | nan              | nan                | nan             | nan              | nan                  | nan                  | nan     | nan     | nan     | nan             |


<br>
<br>
Download full models ranking table: [csv](./results/t5-base_table.csv)